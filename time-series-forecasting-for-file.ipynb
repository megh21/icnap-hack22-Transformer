{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport json\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import layers\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nimport json\nfrom sklearn.preprocessing import StandardScaler\nimport tensorflow \nfrom sklearn import metrics\nimport tensorflow.keras\nfrom tensorflow.keras import layers\nfrom tensorflow import keras\n\nwith open(\"../input/time-series-forecasting/ipt_12.json\") as f:\n    data = json.load(f)\ndf = pd.DataFrame(data)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T03:47:29.715723Z","iopub.execute_input":"2022-05-22T03:47:29.716013Z","iopub.status.idle":"2022-05-22T03:47:32.111570Z","shell.execute_reply.started":"2022-05-22T03:47:29.715981Z","shell.execute_reply":"2022-05-22T03:47:32.110598Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"def convert_to_numpy(series):\n    return np.array(series)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T03:47:32.113746Z","iopub.execute_input":"2022-05-22T03:47:32.114066Z","iopub.status.idle":"2022-05-22T03:47:32.119779Z","shell.execute_reply.started":"2022-05-22T03:47:32.114021Z","shell.execute_reply":"2022-05-22T03:47:32.118223Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"def load_data(data_path):\n    \"\"\"\n    Loading of the dataset provided\n    Edit the code below\n    \"\"\"\n    with open(data_path,\"r\") as f:\n        data = json.load(f)\n    data = pd.DataFrame(data)\n    data = data.drop('94')\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-05-22T03:47:32.121489Z","iopub.execute_input":"2022-05-22T03:47:32.122398Z","iopub.status.idle":"2022-05-22T03:47:32.132134Z","shell.execute_reply.started":"2022-05-22T03:47:32.122335Z","shell.execute_reply":"2022-05-22T03:47:32.131113Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\n\ntrain,test = train_test_split(df, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T03:47:32.135090Z","iopub.execute_input":"2022-05-22T03:47:32.135531Z","iopub.status.idle":"2022-05-22T03:47:32.165596Z","shell.execute_reply.started":"2022-05-22T03:47:32.135485Z","shell.execute_reply":"2022-05-22T03:47:32.164433Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"def shorten_series(data_series):\n    series = np.array(data_series)\n    small_series = []\n    for i in range(0,len(series),8):\n        small_series.append(series[i])\n    return np.array(small_series)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-22T03:47:32.261936Z","iopub.execute_input":"2022-05-22T03:47:32.262350Z","iopub.status.idle":"2022-05-22T03:47:32.268767Z","shell.execute_reply.started":"2022-05-22T03:47:32.262302Z","shell.execute_reply":"2022-05-22T03:47:32.267464Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"def preprocess_data(data):\n    \"\"\"\n    A standard nan removal to be added.\n    Add more preprocessing steps if needed.\n    \"\"\"\n    X = []\n    for i in range(data.shape[0]):\n        series = np.stack((data.iloc[i]['smcAC'],data.iloc[i]['smcDC'],data.iloc[i]['vib_table'],data.iloc[i]['vib_spindle'],data.iloc[i]['AE_table'],data.iloc[i]['AE_spindle']),axis=1)\n        X.append(series.reshape(1125,6))\n    X = np.array(X)\n    y = data['VB'].fillna(data['VB'].mean())\n    return X,y","metadata":{"execution":{"iopub.status.busy":"2022-05-22T03:47:32.270840Z","iopub.execute_input":"2022-05-22T03:47:32.271505Z","iopub.status.idle":"2022-05-22T03:47:32.296041Z","shell.execute_reply.started":"2022-05-22T03:47:32.271459Z","shell.execute_reply":"2022-05-22T03:47:32.286487Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"def split_train_test(X, y):\n    \"\"\"\n    Splitting the data into train, test, validation \n    \"\"\"\n    \n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n    \n    return X_train, X_val, X_test, y_train, y_val, y_test","metadata":{"execution":{"iopub.status.busy":"2022-05-22T03:47:32.301716Z","iopub.execute_input":"2022-05-22T03:47:32.302516Z","iopub.status.idle":"2022-05-22T03:47:32.311928Z","shell.execute_reply.started":"2022-05-22T03:47:32.302467Z","shell.execute_reply":"2022-05-22T03:47:32.310586Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"def normalization(X_train, X_val, X_test):\n    scaler = StandardScaler()\n    shp = X_train.shape[1]\n    X_train = np.reshape(X_train, (-1,shp))\n    X_val = np.reshape(X_val, (-1,shp))\n    X_test = np.reshape(X_test, (-1,shp))\n    \n    X_train = scaler.fit_transform(X_train)\n    X_val = scaler.transform(X_val)\n    X_test = scaler.transform(X_test)\n    \n    return np.reshape(X_train, (-1,shp,1)), np.reshape(X_val, (-1,shp,1)), np.reshape(X_test, (-1,shp,1))","metadata":{"execution":{"iopub.status.busy":"2022-05-22T03:47:32.314390Z","iopub.execute_input":"2022-05-22T03:47:32.315039Z","iopub.status.idle":"2022-05-22T03:47:32.325875Z","shell.execute_reply.started":"2022-05-22T03:47:32.314926Z","shell.execute_reply":"2022-05-22T03:47:32.324412Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"def timeseries_transform(data, head_size, num_heads, ff_dim, dropout=0):\n    \"\"\"\n    Implement the timeseries transformer here\n    \"\"\"\n    # Normalization and Attention\n    x = data\n    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n    x = layers.LayerNormalization(epsilon=1e-6)(x)\n    x = layers.Dropout(dropout)(x)\n    res = x + data\n\n    # Feed Forward Part\n    x = layers.LayerNormalization(epsilon=1e-6)(res)\n    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n    x = layers.Dropout(dropout)(x)\n    x = layers.Conv1D(filters=data.shape[-1], kernel_size=1)(x)\n    return x + res","metadata":{"execution":{"iopub.status.busy":"2022-05-22T03:47:32.328974Z","iopub.execute_input":"2022-05-22T03:47:32.329317Z","iopub.status.idle":"2022-05-22T03:47:32.431255Z","shell.execute_reply.started":"2022-05-22T03:47:32.329273Z","shell.execute_reply":"2022-05-22T03:47:32.429728Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"def build_model(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout=0, mlp_dropout=0):\n    inputs = keras.Input(shape=input_shape)\n    x = inputs\n    for _ in range(num_transformer_blocks):\n        x = timeseries_transform(x, head_size, num_heads, ff_dim, dropout)\n\n    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n    for dim in mlp_units:\n        x = layers.Dense(dim, activation=\"relu\")(x)\n        x = layers.Dropout(mlp_dropout)(x)\n    outputs = layers.Dense(1)(x)\n    return keras.Model(inputs, outputs)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T03:47:32.434909Z","iopub.execute_input":"2022-05-22T03:47:32.435199Z","iopub.status.idle":"2022-05-22T03:47:32.444964Z","shell.execute_reply.started":"2022-05-22T03:47:32.435137Z","shell.execute_reply":"2022-05-22T03:47:32.443847Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"def model_training(X_train, y_train, X_val, y_val):\n    \"\"\"\n    Train the data with the compatible model\n    \"\"\"\n    \n    input_shape = X_train.shape[1:]\n\n    model = build_model(input_shape, head_size=256, num_heads=4, ff_dim=4, num_transformer_blocks=4, mlp_units=[128], mlp_dropout=0.4, dropout=0.35)\n    lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-4, decay_steps=10000, decay_rate=0.9)\n\n    model.compile(\n        loss=\"mse\",\n        optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n        metrics=[tensorflow.keras.metrics.MeanSquaredError()],\n    )\n    \n    model.summary()\n\n    callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n\n    model.fit(X_train, y_train, validation_data=(X_val,y_val),  epochs=200, batch_size=16, callbacks=callbacks)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-22T03:47:32.446827Z","iopub.execute_input":"2022-05-22T03:47:32.447218Z","iopub.status.idle":"2022-05-22T03:47:32.459878Z","shell.execute_reply.started":"2022-05-22T03:47:32.447139Z","shell.execute_reply":"2022-05-22T03:47:32.458758Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"def metric(y_act, y_pred):\n    \"\"\"\n    Standard metrics and plotting should be same\n    Metrics should be computed on validation data(unseen data)\n    1. Balanced accuracy score\n    2. Confusion matrix\n    3. Per-class accuracy\n    \"\"\"\n    \n    cm = metrics.confusion_matrix(y_act, y_pred)\n    balanced_accuracy = metrics.balanced_accuracy_score(y_act, y_pred)\n    \n    return cm, balanced_accuracy","metadata":{"execution":{"iopub.status.busy":"2022-05-22T03:47:32.461866Z","iopub.execute_input":"2022-05-22T03:47:32.462176Z","iopub.status.idle":"2022-05-22T03:47:32.472125Z","shell.execute_reply.started":"2022-05-22T03:47:32.462145Z","shell.execute_reply":"2022-05-22T03:47:32.471074Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"def validation(X_val, y_val, metric):\n    \"\"\"\n    Comparing the results with provided Series Embedder\n    Plot confusion matrices of self analysis and LSTM with balanced_accuracy\n    \n    \"\"\"\n    \n    score = model.evaluate(X_val, y_val, verbose=1)\n    \n    return score","metadata":{"execution":{"iopub.status.busy":"2022-05-22T03:47:32.474949Z","iopub.execute_input":"2022-05-22T03:47:32.475666Z","iopub.status.idle":"2022-05-22T03:47:32.483502Z","shell.execute_reply.started":"2022-05-22T03:47:32.475617Z","shell.execute_reply":"2022-05-22T03:47:32.482220Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"def evaluate(X_test, y_act, metric, model):\n    y_pred = model.predict(X_test, verbose=1)\n    cm, ba = metric(y_act, y_pred)\n    \n    return y_pred, cm, ba","metadata":{"execution":{"iopub.status.busy":"2022-05-22T03:47:32.487281Z","iopub.execute_input":"2022-05-22T03:47:32.487580Z","iopub.status.idle":"2022-05-22T03:47:32.498040Z","shell.execute_reply.started":"2022-05-22T03:47:32.487519Z","shell.execute_reply":"2022-05-22T03:47:32.497074Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"path = \"../input/time-series-forecasting/ipt_12.json\"\ndata = load_data(path)\ndata = data.head()\ndata['smcAC'] = data['smcAC'].apply(lambda x:shorten_series(x))\ndata['smcDC'] = data['smcDC'].apply(lambda x:shorten_series(x))\ndata['vib_table'] = data['vib_table'].apply(lambda x:shorten_series(x))\ndata['vib_spindle'] = data['vib_spindle'].apply(lambda x:shorten_series(x))\ndata['AE_table'] = data['AE_table'].apply(lambda x:shorten_series(x))\ndata['AE_spindle'] = data['AE_spindle'].apply(lambda x:shorten_series(x))\nX, y = preprocess_data(data)\n\nX_train, X_val, X_test, y_train, y_val, y_test = split_train_test(X, y)\nmodel_self=model_training(X_train, y_train, X_val, y_val)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-22T03:47:32.499837Z","iopub.execute_input":"2022-05-22T03:47:32.500489Z","iopub.status.idle":"2022-05-22T03:47:43.113830Z","shell.execute_reply.started":"2022-05-22T03:47:32.500435Z","shell.execute_reply":"2022-05-22T03:47:43.112877Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"Model: \"model_4\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_5 (InputLayer)            [(None, 1125, 6)]    0                                            \n__________________________________________________________________________________________________\nmulti_head_attention_16 (MultiH (None, 1125, 6)      27654       input_5[0][0]                    \n                                                                 input_5[0][0]                    \n__________________________________________________________________________________________________\nlayer_normalization_32 (LayerNo (None, 1125, 6)      12          multi_head_attention_16[0][0]    \n__________________________________________________________________________________________________\ndropout_36 (Dropout)            (None, 1125, 6)      0           layer_normalization_32[0][0]     \n__________________________________________________________________________________________________\ntf.__operators__.add_32 (TFOpLa (None, 1125, 6)      0           dropout_36[0][0]                 \n                                                                 input_5[0][0]                    \n__________________________________________________________________________________________________\nlayer_normalization_33 (LayerNo (None, 1125, 6)      12          tf.__operators__.add_32[0][0]    \n__________________________________________________________________________________________________\nconv1d_32 (Conv1D)              (None, 1125, 4)      28          layer_normalization_33[0][0]     \n__________________________________________________________________________________________________\ndropout_37 (Dropout)            (None, 1125, 4)      0           conv1d_32[0][0]                  \n__________________________________________________________________________________________________\nconv1d_33 (Conv1D)              (None, 1125, 6)      30          dropout_37[0][0]                 \n__________________________________________________________________________________________________\ntf.__operators__.add_33 (TFOpLa (None, 1125, 6)      0           conv1d_33[0][0]                  \n                                                                 tf.__operators__.add_32[0][0]    \n__________________________________________________________________________________________________\nmulti_head_attention_17 (MultiH (None, 1125, 6)      27654       tf.__operators__.add_33[0][0]    \n                                                                 tf.__operators__.add_33[0][0]    \n__________________________________________________________________________________________________\nlayer_normalization_34 (LayerNo (None, 1125, 6)      12          multi_head_attention_17[0][0]    \n__________________________________________________________________________________________________\ndropout_38 (Dropout)            (None, 1125, 6)      0           layer_normalization_34[0][0]     \n__________________________________________________________________________________________________\ntf.__operators__.add_34 (TFOpLa (None, 1125, 6)      0           dropout_38[0][0]                 \n                                                                 tf.__operators__.add_33[0][0]    \n__________________________________________________________________________________________________\nlayer_normalization_35 (LayerNo (None, 1125, 6)      12          tf.__operators__.add_34[0][0]    \n__________________________________________________________________________________________________\nconv1d_34 (Conv1D)              (None, 1125, 4)      28          layer_normalization_35[0][0]     \n__________________________________________________________________________________________________\ndropout_39 (Dropout)            (None, 1125, 4)      0           conv1d_34[0][0]                  \n__________________________________________________________________________________________________\nconv1d_35 (Conv1D)              (None, 1125, 6)      30          dropout_39[0][0]                 \n__________________________________________________________________________________________________\ntf.__operators__.add_35 (TFOpLa (None, 1125, 6)      0           conv1d_35[0][0]                  \n                                                                 tf.__operators__.add_34[0][0]    \n__________________________________________________________________________________________________\nmulti_head_attention_18 (MultiH (None, 1125, 6)      27654       tf.__operators__.add_35[0][0]    \n                                                                 tf.__operators__.add_35[0][0]    \n__________________________________________________________________________________________________\nlayer_normalization_36 (LayerNo (None, 1125, 6)      12          multi_head_attention_18[0][0]    \n__________________________________________________________________________________________________\ndropout_40 (Dropout)            (None, 1125, 6)      0           layer_normalization_36[0][0]     \n__________________________________________________________________________________________________\ntf.__operators__.add_36 (TFOpLa (None, 1125, 6)      0           dropout_40[0][0]                 \n                                                                 tf.__operators__.add_35[0][0]    \n__________________________________________________________________________________________________\nlayer_normalization_37 (LayerNo (None, 1125, 6)      12          tf.__operators__.add_36[0][0]    \n__________________________________________________________________________________________________\nconv1d_36 (Conv1D)              (None, 1125, 4)      28          layer_normalization_37[0][0]     \n__________________________________________________________________________________________________\ndropout_41 (Dropout)            (None, 1125, 4)      0           conv1d_36[0][0]                  \n__________________________________________________________________________________________________\nconv1d_37 (Conv1D)              (None, 1125, 6)      30          dropout_41[0][0]                 \n__________________________________________________________________________________________________\ntf.__operators__.add_37 (TFOpLa (None, 1125, 6)      0           conv1d_37[0][0]                  \n                                                                 tf.__operators__.add_36[0][0]    \n__________________________________________________________________________________________________\nmulti_head_attention_19 (MultiH (None, 1125, 6)      27654       tf.__operators__.add_37[0][0]    \n                                                                 tf.__operators__.add_37[0][0]    \n__________________________________________________________________________________________________\nlayer_normalization_38 (LayerNo (None, 1125, 6)      12          multi_head_attention_19[0][0]    \n__________________________________________________________________________________________________\ndropout_42 (Dropout)            (None, 1125, 6)      0           layer_normalization_38[0][0]     \n__________________________________________________________________________________________________\ntf.__operators__.add_38 (TFOpLa (None, 1125, 6)      0           dropout_42[0][0]                 \n                                                                 tf.__operators__.add_37[0][0]    \n__________________________________________________________________________________________________\nlayer_normalization_39 (LayerNo (None, 1125, 6)      12          tf.__operators__.add_38[0][0]    \n__________________________________________________________________________________________________\nconv1d_38 (Conv1D)              (None, 1125, 4)      28          layer_normalization_39[0][0]     \n__________________________________________________________________________________________________\ndropout_43 (Dropout)            (None, 1125, 4)      0           conv1d_38[0][0]                  \n__________________________________________________________________________________________________\nconv1d_39 (Conv1D)              (None, 1125, 6)      30          dropout_43[0][0]                 \n__________________________________________________________________________________________________\ntf.__operators__.add_39 (TFOpLa (None, 1125, 6)      0           conv1d_39[0][0]                  \n                                                                 tf.__operators__.add_38[0][0]    \n__________________________________________________________________________________________________\nglobal_average_pooling1d_4 (Glo (None, 1125)         0           tf.__operators__.add_39[0][0]    \n__________________________________________________________________________________________________\ndense_11 (Dense)                (None, 128)          144128      global_average_pooling1d_4[0][0] \n__________________________________________________________________________________________________\ndropout_44 (Dropout)            (None, 128)          0           dense_11[0][0]                   \n__________________________________________________________________________________________________\ndense_12 (Dense)                (None, 1)            129         dropout_44[0][0]                 \n==================================================================================================\nTotal params: 255,201\nTrainable params: 255,201\nNon-trainable params: 0\n__________________________________________________________________________________________________\nEpoch 1/200\n1/1 [==============================] - 5s 5s/step - loss: 1.0385 - mean_squared_error: 1.0385 - val_loss: 3.2948 - val_mean_squared_error: 3.2948\nEpoch 2/200\n1/1 [==============================] - 0s 93ms/step - loss: 1.8274 - mean_squared_error: 1.8274 - val_loss: 7.1610 - val_mean_squared_error: 7.1610\nEpoch 3/200\n1/1 [==============================] - 0s 91ms/step - loss: 2.6792 - mean_squared_error: 2.6792 - val_loss: 7.6677 - val_mean_squared_error: 7.6677\nEpoch 4/200\n1/1 [==============================] - 0s 96ms/step - loss: 10.7186 - mean_squared_error: 10.7186 - val_loss: 4.6808 - val_mean_squared_error: 4.6808\nEpoch 5/200\n1/1 [==============================] - 0s 90ms/step - loss: 0.5770 - mean_squared_error: 0.5770 - val_loss: 2.3353 - val_mean_squared_error: 2.3353\nEpoch 6/200\n1/1 [==============================] - 0s 87ms/step - loss: 8.3192 - mean_squared_error: 8.3192 - val_loss: 0.6934 - val_mean_squared_error: 0.6934\nEpoch 7/200\n1/1 [==============================] - 0s 87ms/step - loss: 15.7554 - mean_squared_error: 15.7554 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\nEpoch 8/200\n1/1 [==============================] - 0s 86ms/step - loss: 8.5230 - mean_squared_error: 8.5230 - val_loss: 0.0490 - val_mean_squared_error: 0.0490\nEpoch 9/200\n1/1 [==============================] - 0s 89ms/step - loss: 9.3291 - mean_squared_error: 9.3291 - val_loss: 0.1088 - val_mean_squared_error: 0.1088\nEpoch 10/200\n1/1 [==============================] - 0s 89ms/step - loss: 7.7370 - mean_squared_error: 7.7370 - val_loss: 0.0840 - val_mean_squared_error: 0.0840\nEpoch 11/200\n1/1 [==============================] - 0s 87ms/step - loss: 1.9154 - mean_squared_error: 1.9154 - val_loss: 0.1236 - val_mean_squared_error: 0.1236\nEpoch 12/200\n1/1 [==============================] - 0s 88ms/step - loss: 2.9930 - mean_squared_error: 2.9930 - val_loss: 0.0972 - val_mean_squared_error: 0.0972\nEpoch 13/200\n1/1 [==============================] - 0s 99ms/step - loss: 3.0885 - mean_squared_error: 3.0885 - val_loss: 0.0487 - val_mean_squared_error: 0.0487\nEpoch 14/200\n1/1 [==============================] - 0s 87ms/step - loss: 4.0484 - mean_squared_error: 4.0484 - val_loss: 0.0586 - val_mean_squared_error: 0.0586\nEpoch 15/200\n1/1 [==============================] - 0s 90ms/step - loss: 2.5416 - mean_squared_error: 2.5416 - val_loss: 0.1266 - val_mean_squared_error: 0.1266\nEpoch 16/200\n1/1 [==============================] - 0s 100ms/step - loss: 9.2998 - mean_squared_error: 9.2998 - val_loss: 0.3014 - val_mean_squared_error: 0.3014\nEpoch 17/200\n1/1 [==============================] - 0s 87ms/step - loss: 3.6949 - mean_squared_error: 3.6949 - val_loss: 0.5569 - val_mean_squared_error: 0.5569\n","output_type":"stream"}]},{"cell_type":"code","source":"model_self.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T03:49:56.222135Z","iopub.execute_input":"2022-05-22T03:49:56.222499Z","iopub.status.idle":"2022-05-22T03:49:56.322659Z","shell.execute_reply.started":"2022-05-22T03:49:56.222456Z","shell.execute_reply":"2022-05-22T03:49:56.321465Z"},"trusted":true},"execution_count":70,"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"array([[0.8393218]], dtype=float32)"},"metadata":{}}]}]}