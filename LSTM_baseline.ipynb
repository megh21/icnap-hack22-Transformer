{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6030ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_0</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.79717168, -0.66439208, -0.37301463, 0.0408...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.80485472, 0.63462859, 0.37347448, 0.0383434...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.7279851, 0.11128392, -0.49912439, -1.068629...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.23443909, -0.50215697, -0.73248781, -0.946...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.17132785, -0.062285311, 0.235829, 0.710395...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               dim_0 labels\n",
       "0  [-0.79717168, -0.66439208, -0.37301463, 0.0408...     -1\n",
       "1  [0.80485472, 0.63462859, 0.37347448, 0.0383434...      1\n",
       "2  [0.7279851, 0.11128392, -0.49912439, -1.068629...     -1\n",
       "3  [-0.23443909, -0.50215697, -0.73248781, -0.946...     -1\n",
       "4  [-0.17132785, -0.062285311, 0.235829, 0.710395...     -1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense,Flatten,Dropout\n",
    "\n",
    "df = pd.read_pickle(\"FordA\\data.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ccd3a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(df.dim_0.tolist())\n",
    "X = X.to_numpy()\n",
    "\n",
    "y = df[\"labels\"].to_numpy(dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d86f4a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dimenstion_mod(x):\n",
    "#     a = list()\n",
    "#     for i in range(x.shape[0]):\n",
    "#         a.append(x[i])\n",
    "#     a = np.array(a) \n",
    "#     return np.reshape(a, (a.shape[0], a.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b55e37d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X =  df[df.columns.drop(\"labels\")].to_numpy()\n",
    "# y = df[\"labels\"].to_numpy(dtype=int)\n",
    "\n",
    "y = np.where(y == -1, 0, y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train)\n",
    "\n",
    "# X_train = dimenstion_mod(X_train)\n",
    "# X_val = dimenstion_mod(X_val)\n",
    "# X_test = dimenstion_mod(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d50142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(100,\n",
    "            return_sequences=True,\n",
    "            input_shape=(X_train.shape[1],1)))\n",
    "model.add(LSTM(200, return_sequences=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "#model.add(LSTM(20))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.binary_crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a94c644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.6386WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 20 batches). You may need to use the repeat() function when building your dataset.\n",
      "32/32 [==============================] - 8s 158ms/step - loss: 0.6386 - val_loss: 0.6155\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 0.5553\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 0.5104\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 0.4504\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 0.3919\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 0.3375\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 3s 109ms/step - loss: 0.2911\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 0.2156\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 0.1367\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 3s 109ms/step - loss: 0.1004\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 0.0634\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 0.0550\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 0.0387\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 0.0246\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 0.0296\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 0.0373\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 3s 109ms/step - loss: 0.0198\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 0.0142\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 4s 109ms/step - loss: 0.0103\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 3s 109ms/step - loss: 0.0076\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 0.0023\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 5.0988e-04\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 5.7304e-04\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 1.9055e-04\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 1.6170e-04\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 1.4146e-04\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 1.1962e-04\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 9.1804e-05\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 9.1679e-05\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 9.4460e-05\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 7.7944e-05\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 6.2342e-05\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 1.3676e-04\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 7.5831e-05\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 6.8434e-05\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 6.1055e-05\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 4.6983e-05\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 4.7111e-05\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 4.4573e-05\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 5.2320e-05\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 4.0127e-05\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 2.7277e-05\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 2.9329e-05\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 2.7047e-05\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 3.7844e-05\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 4.2418e-05\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 2.9225e-05\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 3.4250e-05\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 2.3106e-05\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 2.4643e-05\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 2.5975e-05\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 2.5361e-05\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 4s 109ms/step - loss: 1.9661e-05\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 2.1458e-05\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 1.8818e-05\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 3.6809e-05\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 2.2977e-05\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 4s 109ms/step - loss: 2.0089e-05\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 1.3829e-05\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 1.5075e-05\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 3s 109ms/step - loss: 1.9379e-05\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 1.1495e-05\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 1.3113e-05\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 4s 109ms/step - loss: 1.2787e-05\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 3s 109ms/step - loss: 1.4793e-05\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 9.7174e-06\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 1.5148e-05\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 9.6422e-06\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 1.2529e-05\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 1.2519e-05\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 1.0444e-05\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 9.7910e-06\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 1.0090e-05\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 8.4277e-06\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 1.3497e-05\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 4s 113ms/step - loss: 1.0716e-05\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 7.6994e-06\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 9.5821e-06\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 8.5782e-06\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 4s 113ms/step - loss: 6.6130e-06\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 7.4893e-06\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 7.5645e-06\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 7.7225e-06\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 8.7195e-06\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 8.0126e-06\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 8.3086e-06\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 4s 123ms/step - loss: 5.6567e-06\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 5.8504e-06\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 5.6505e-06\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 9.6460e-06\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 5.2947e-06\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 4s 110ms/step - loss: 6.5519e-06\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 5.7396e-06\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 5.7492e-06\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 3.8979e-06\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 5.5613e-06\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 3.4903e-06\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 6.9615e-06\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 4.6892e-06\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 3s 109ms/step - loss: 5.9959e-06\n",
      "25/25 [==============================] - 1s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,epochs=100, validation_data=(X_val, y_val), validation_steps = 20 ,batch_size=100)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.where(y_pred > 0.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acfc5f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[333  72]\n",
      " [ 66 317]]\n",
      "0.8249492312155497\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(y_test, y_pred[:,0])\n",
    "balanced_accuracy = metrics.balanced_accuracy_score(y_test, y_pred[:,0])\n",
    "print(cm)\n",
    "print(balanced_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
