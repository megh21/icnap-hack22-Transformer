{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport json\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import layers\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nimport json\nfrom sklearn.preprocessing import StandardScaler\nimport tensorflow \nfrom sklearn import metrics\nimport tensorflow.keras\nfrom tensorflow.keras import layers\nfrom tensorflow import keras\n\nwith open(\"../input/regdata/ipt_12.json\") as f:\n    data = json.load(f)\ndf = pd.DataFrame(data)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T10:37:36.485053Z","iopub.execute_input":"2022-05-22T10:37:36.485387Z","iopub.status.idle":"2022-05-22T10:37:45.141460Z","shell.execute_reply.started":"2022-05-22T10:37:36.485361Z","shell.execute_reply":"2022-05-22T10:37:45.140715Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def convert_to_numpy(series):\n    return np.array(series)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T10:37:45.143151Z","iopub.execute_input":"2022-05-22T10:37:45.143413Z","iopub.status.idle":"2022-05-22T10:37:45.149296Z","shell.execute_reply.started":"2022-05-22T10:37:45.143384Z","shell.execute_reply":"2022-05-22T10:37:45.146641Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def load_data(data_path):\n    \"\"\"\n    Loading of the dataset provided\n    Edit the code below\n    \"\"\"\n    with open(data_path,\"r\") as f:\n        data = json.load(f)\n    data = pd.DataFrame(data)\n    data = data.drop('94')\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-05-22T10:37:45.151767Z","iopub.execute_input":"2022-05-22T10:37:45.152939Z","iopub.status.idle":"2022-05-22T10:37:45.166484Z","shell.execute_reply.started":"2022-05-22T10:37:45.152854Z","shell.execute_reply":"2022-05-22T10:37:45.165738Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\n\ntrain,test = train_test_split(df, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T10:37:45.168519Z","iopub.execute_input":"2022-05-22T10:37:45.168822Z","iopub.status.idle":"2022-05-22T10:37:45.180660Z","shell.execute_reply.started":"2022-05-22T10:37:45.168750Z","shell.execute_reply":"2022-05-22T10:37:45.179938Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def shorten_series(data_series):\n    series = np.array(data_series)\n    small_series = []\n    for i in range(0,len(series),10):\n        if i !=0:\n            small_series.append(np.mean(series[i-10:i]))\n        else: \n            small_series.append(series[0])\n    return np.array(small_series)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-22T10:37:45.183655Z","iopub.execute_input":"2022-05-22T10:37:45.183863Z","iopub.status.idle":"2022-05-22T10:37:45.195718Z","shell.execute_reply.started":"2022-05-22T10:37:45.183841Z","shell.execute_reply":"2022-05-22T10:37:45.195090Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def preprocess_data(data):\n    \"\"\"\n    A standard nan removal to be added.\n    Add more preprocessing steps if needed.\n    \"\"\"\n    X = []\n    for i in range(data.shape[0]):\n        series = np.stack((data.iloc[i]['smcAC'],data.iloc[i]['smcDC'],data.iloc[i]['vib_table'],data.iloc[i]['vib_spindle'],data.iloc[i]['AE_table'],data.iloc[i]['AE_spindle']),axis=1)\n        X.append(series.reshape(900,6))\n    X = np.array(X)\n    y = data['VB'].fillna(data['VB'].mean())\n    return X,y","metadata":{"execution":{"iopub.status.busy":"2022-05-22T10:37:45.197661Z","iopub.execute_input":"2022-05-22T10:37:45.198091Z","iopub.status.idle":"2022-05-22T10:37:45.208169Z","shell.execute_reply.started":"2022-05-22T10:37:45.198058Z","shell.execute_reply":"2022-05-22T10:37:45.207425Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def split_train_test(X, y):\n    \"\"\"\n    Splitting the data into train, test, validation \n    \"\"\"\n    \n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n    \n    return X_train, X_val, X_test, y_train, y_val, y_test","metadata":{"execution":{"iopub.status.busy":"2022-05-22T10:37:45.209997Z","iopub.execute_input":"2022-05-22T10:37:45.210439Z","iopub.status.idle":"2022-05-22T10:37:45.216694Z","shell.execute_reply.started":"2022-05-22T10:37:45.210405Z","shell.execute_reply":"2022-05-22T10:37:45.216037Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def normalization(X_train, X_val, X_test):\n    scaler = StandardScaler()\n    shp = X_train.shape[1]\n    X_train = np.reshape(X_train, (-1,shp))\n    X_val = np.reshape(X_val, (-1,shp))\n    X_test = np.reshape(X_test, (-1,shp))\n    \n    X_train = scaler.fit_transform(X_train)\n    X_val = scaler.transform(X_val)\n    X_test = scaler.transform(X_test)\n    \n    return np.reshape(X_train, (-1,shp,1)), np.reshape(X_val, (-1,shp,1)), np.reshape(X_test, (-1,shp,1))","metadata":{"execution":{"iopub.status.busy":"2022-05-22T10:37:45.218721Z","iopub.execute_input":"2022-05-22T10:37:45.219184Z","iopub.status.idle":"2022-05-22T10:37:45.226413Z","shell.execute_reply.started":"2022-05-22T10:37:45.219149Z","shell.execute_reply":"2022-05-22T10:37:45.225758Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def timeseries_transform(data, head_size, num_heads, ff_dim, dropout=0):\n    \"\"\"\n    Implement the timeseries transformer here\n    \"\"\"\n    # Normalization and Attention\n    x = data\n    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n    x = layers.LayerNormalization(epsilon=1e-6)(x)\n\n\n    res = x + data\n    res = layers.MaxPooling1D((1))(res) \n    # Feed Forward Part\n    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n    x = layers.MaxPooling1D(pool_size=1)(x)\n    x = layers.LayerNormalization(epsilon=1e-6)(x)\n    x = layers.Conv1D(filters=data.shape[-1], kernel_size=1)(x)\n    return x + res","metadata":{"execution":{"iopub.status.busy":"2022-05-22T10:37:45.227658Z","iopub.execute_input":"2022-05-22T10:37:45.228153Z","iopub.status.idle":"2022-05-22T10:37:45.236117Z","shell.execute_reply.started":"2022-05-22T10:37:45.228118Z","shell.execute_reply":"2022-05-22T10:37:45.235309Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def build_model(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout=0, mlp_dropout=0):\n    inputs = keras.Input(shape=input_shape)\n    x = inputs\n    for i in range(3):\n        for _ in range(num_transformer_blocks):\n            x = timeseries_transform(x, head_size, num_heads, ff_dim, dropout)\n\n    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n    for dim in mlp_units:\n        x = layers.Dense(dim, activation=\"relu\")(x)\n    x = layers.Dense(128, activation=\"relu\")(x)\n    outputs = layers.Dense(1)(x)\n    return keras.Model(inputs, outputs)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T10:37:45.238653Z","iopub.execute_input":"2022-05-22T10:37:45.239121Z","iopub.status.idle":"2022-05-22T10:37:45.247685Z","shell.execute_reply.started":"2022-05-22T10:37:45.239089Z","shell.execute_reply":"2022-05-22T10:37:45.246981Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def model_training(X_train, y_train, X_val, y_val):\n    \"\"\"\n    Train the data with the compatible model\n    \"\"\"\n    \n    input_shape = X_train.shape[1:]\n\n    model = build_model(input_shape, head_size=256, num_heads=4, ff_dim=4, num_transformer_blocks=4, mlp_units=[128], mlp_dropout=0.4, dropout=0.0)\n    lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-4, decay_steps=10000, decay_rate=0.9)\n\n    model.compile(\n        loss=\"mse\",\n        optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n        metrics=[tensorflow.keras.metrics.MeanSquaredError()],\n    )\n    \n    model.summary()\n\n    callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n\n    model.fit(X_train, y_train, validation_data=(X_val,y_val),  epochs=200, batch_size=16, callbacks=callbacks)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-22T10:37:45.248952Z","iopub.execute_input":"2022-05-22T10:37:45.249287Z","iopub.status.idle":"2022-05-22T10:37:45.257423Z","shell.execute_reply.started":"2022-05-22T10:37:45.249251Z","shell.execute_reply":"2022-05-22T10:37:45.256683Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def metric(y_act, y_pred):\n    \"\"\"\n    Standard metrics and plotting should be same\n    Metrics should be computed on validation data(unseen data)\n    1. Balanced accuracy score\n    2. Confusion matrix\n    3. Per-class accuracy\n    \"\"\"\n    \n    cm = metrics.confusion_matrix(y_act, y_pred)\n    balanced_accuracy = metrics.balanced_accuracy_score(y_act, y_pred)\n    \n    return cm, balanced_accuracy","metadata":{"execution":{"iopub.status.busy":"2022-05-22T10:37:45.258653Z","iopub.execute_input":"2022-05-22T10:37:45.259068Z","iopub.status.idle":"2022-05-22T10:37:45.268117Z","shell.execute_reply.started":"2022-05-22T10:37:45.259035Z","shell.execute_reply":"2022-05-22T10:37:45.267331Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def validation(X_val, y_val, metric):\n    \"\"\"\n    Comparing the results with provided Series Embedder\n    Plot confusion matrices of self analysis and LSTM with balanced_accuracy\n    \n    \"\"\"\n    \n    score = model.evaluate(X_val, y_val, verbose=1)\n    \n    return score","metadata":{"execution":{"iopub.status.busy":"2022-05-22T10:37:45.271056Z","iopub.execute_input":"2022-05-22T10:37:45.271654Z","iopub.status.idle":"2022-05-22T10:37:45.277451Z","shell.execute_reply.started":"2022-05-22T10:37:45.271625Z","shell.execute_reply":"2022-05-22T10:37:45.276735Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def evaluate(X_test, y_act, metric, model):\n    y_pred = model.predict(X_test, verbose=1)\n    cm, ba = metric(y_act, y_pred)\n    \n    return y_pred, cm, ba","metadata":{"execution":{"iopub.status.busy":"2022-05-22T10:37:45.280324Z","iopub.execute_input":"2022-05-22T10:37:45.280829Z","iopub.status.idle":"2022-05-22T10:37:45.285924Z","shell.execute_reply.started":"2022-05-22T10:37:45.280773Z","shell.execute_reply":"2022-05-22T10:37:45.285250Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"path = \"../input/regdata/ipt_12.json\"\ndata = load_data(path)\ndata = data.head(55)\ndata['smcAC'] = data['smcAC'].apply(lambda x:shorten_series(x))\ndata['smcDC'] = data['smcDC'].apply(lambda x:shorten_series(x))\ndata['vib_table'] = data['vib_table'].apply(lambda x:shorten_series(x))\ndata['vib_spindle'] = data['vib_spindle'].apply(lambda x:shorten_series(x))\ndata['AE_table'] = data['AE_table'].apply(lambda x:shorten_series(x))\ndata['AE_spindle'] = data['AE_spindle'].apply(lambda x:shorten_series(x))\nX, y = preprocess_data(data)\n\nX_train, X_val, X_test, y_train, y_val, y_test = split_train_test(X, y)\nmodel_self=model_training(X_train, y_train, X_val, y_val)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-22T10:37:45.287021Z","iopub.execute_input":"2022-05-22T10:37:45.287404Z","iopub.status.idle":"2022-05-22T10:38:46.094929Z","shell.execute_reply.started":"2022-05-22T10:37:45.287370Z","shell.execute_reply":"2022-05-22T10:38:46.094195Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"y_pred=model_self.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T10:38:46.099500Z","iopub.execute_input":"2022-05-22T10:38:46.101658Z","iopub.status.idle":"2022-05-22T10:39:25.971657Z","shell.execute_reply.started":"2022-05-22T10:38:46.101620Z","shell.execute_reply":"2022-05-22T10:39:25.970898Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"print(y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T10:39:44.342413Z","iopub.execute_input":"2022-05-22T10:39:44.342962Z","iopub.status.idle":"2022-05-22T10:39:44.349110Z","shell.execute_reply.started":"2022-05-22T10:39:44.342923Z","shell.execute_reply":"2022-05-22T10:39:44.348305Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"print(y_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T10:39:55.292565Z","iopub.execute_input":"2022-05-22T10:39:55.292852Z","iopub.status.idle":"2022-05-22T10:39:55.300296Z","shell.execute_reply.started":"2022-05-22T10:39:55.292818Z","shell.execute_reply":"2022-05-22T10:39:55.299488Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}