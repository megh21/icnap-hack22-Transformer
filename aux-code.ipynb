{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sktime","metadata":{"execution":{"iopub.status.busy":"2022-05-22T01:28:22.228647Z","iopub.execute_input":"2022-05-22T01:28:22.228935Z","iopub.status.idle":"2022-05-22T01:28:32.329492Z","shell.execute_reply.started":"2022-05-22T01:28:22.228905Z","shell.execute_reply":"2022-05-22T01:28:32.328530Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Requirement already satisfied: sktime in /opt/conda/lib/python3.7/site-packages (0.11.4)\nRequirement already satisfied: deprecated>=1.2.13 in /opt/conda/lib/python3.7/site-packages (from sktime) (1.2.13)\nRequirement already satisfied: pandas<1.5.0,>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from sktime) (1.3.5)\nRequirement already satisfied: numba>=0.53 in /opt/conda/lib/python3.7/site-packages (from sktime) (0.55.1)\nRequirement already satisfied: scikit-learn<1.2.0,>=0.24.0 in /opt/conda/lib/python3.7/site-packages (from sktime) (1.0.2)\nRequirement already satisfied: statsmodels>=0.12.1 in /opt/conda/lib/python3.7/site-packages (from sktime) (0.13.2)\nRequirement already satisfied: numpy<1.22,>=1.21.0 in /opt/conda/lib/python3.7/site-packages (from sktime) (1.21.6)\nRequirement already satisfied: scipy<1.9.0 in /opt/conda/lib/python3.7/site-packages (from sktime) (1.7.3)\nRequirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from deprecated>=1.2.13->sktime) (1.14.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba>=0.53->sktime) (59.8.0)\nRequirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /opt/conda/lib/python3.7/site-packages (from numba>=0.53->sktime) (0.38.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas<1.5.0,>=1.1.0->sktime) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas<1.5.0,>=1.1.0->sktime) (2021.3)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn<1.2.0,>=0.24.0->sktime) (1.0.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn<1.2.0,>=0.24.0->sktime) (3.1.0)\nRequirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.7/site-packages (from statsmodels>=0.12.1->sktime) (0.5.2)\nRequirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.7/site-packages (from statsmodels>=0.12.1->sktime) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=21.3->statsmodels>=0.12.1->sktime) (3.0.7)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from patsy>=0.5.2->statsmodels>=0.12.1->sktime) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"\nHackathon - INCAP - IconPro GmbH\nTimeseries Classification with Transformers\n\"\"\"\nimport pandas as pd\nfrom tensorflow import keras\nfrom dataclasses import dataclass\nfrom tensorflow.keras import layers\nimport os\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import metrics\nfrom sklearn.linear_model import RidgeClassifierCV\nfrom sklearn.pipeline import make_pipeline\nfrom sktime.transformations.panel.rocket import Rocket, MiniRocket\n# Import packages as you need","metadata":{"execution":{"iopub.status.busy":"2022-05-22T01:28:32.333639Z","iopub.execute_input":"2022-05-22T01:28:32.333887Z","iopub.status.idle":"2022-05-22T01:28:32.341999Z","shell.execute_reply.started":"2022-05-22T01:28:32.333858Z","shell.execute_reply":"2022-05-22T01:28:32.341169Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def load_data(data_path):\n    \"\"\"\n    Loading of the dataset provided\n    Edit the code below\n    \"\"\"\n    data = pd.read_pickle(data_path)\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-05-22T01:28:32.344241Z","iopub.execute_input":"2022-05-22T01:28:32.344530Z","iopub.status.idle":"2022-05-22T01:28:32.351600Z","shell.execute_reply.started":"2022-05-22T01:28:32.344491Z","shell.execute_reply":"2022-05-22T01:28:32.350784Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def preprocess_data(data):\n    \"\"\"\n    A standard nan removal to be added.\n    Add more preprocessing steps if needed.\n    \"\"\"\n    \n    X = data['dim_0'].apply(lambda x: x.reshape(500,1))\n    \n    for i in range(data.shape[0]):\n        if True in np.isnan(data['dim_0'][i]).flatten():\n            print(i)\n            \n    input_x = []\n    for array in X:\n        input_x.append(array)\n    \n#     X = pd.DataFrame(data.dim_0.tolist())\n#     X = X.to_numpy()\n    \n    y = data['labels']\n    y = y.astype(int)\n    y[y == -1] = 0\n    return input_x,y","metadata":{"execution":{"iopub.status.busy":"2022-05-22T01:28:32.354640Z","iopub.execute_input":"2022-05-22T01:28:32.354890Z","iopub.status.idle":"2022-05-22T01:28:32.364615Z","shell.execute_reply.started":"2022-05-22T01:28:32.354863Z","shell.execute_reply":"2022-05-22T01:28:32.363792Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def Rocket_preprocessing(input_x):\n    input_x1=[]\n    input_x = np.array(input_x).reshape(4921, 500)\n    for i in range(input_x.shape[0]):\n        input_x1.append(pd.Series(input_x[i]))\n    input_x1=pd.Series(input_x1)\n    \n    input_x1=pd.DataFrame(input_x1)\n    return input_x1","metadata":{"execution":{"iopub.status.busy":"2022-05-22T01:28:32.366503Z","iopub.execute_input":"2022-05-22T01:28:32.367714Z","iopub.status.idle":"2022-05-22T01:28:32.374896Z","shell.execute_reply.started":"2022-05-22T01:28:32.367673Z","shell.execute_reply":"2022-05-22T01:28:32.373787Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def split_train_test(X, y):\n    \"\"\"\n    Splitting the data into train, test, validation \n    \"\"\"\n    \n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n    \n    return X_train, X_val, X_test, y_train, y_val, y_test","metadata":{"execution":{"iopub.status.busy":"2022-05-22T01:28:32.376636Z","iopub.execute_input":"2022-05-22T01:28:32.377701Z","iopub.status.idle":"2022-05-22T01:28:32.385022Z","shell.execute_reply.started":"2022-05-22T01:28:32.377660Z","shell.execute_reply":"2022-05-22T01:28:32.384114Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def Rocket(X_train, X_val, X_test):\n    rocket = MiniRocket(num_kernels=500)  # by default, ROCKET uses 10,000 kernels\n    X_train = rocket.fit_transform(X_train)\n    X_train = np.expand_dims(np.array(X_train), axis=2)\n    \n    X_val = rocket.transform(X_val)\n    X_val = np.expand_dims(np.array(X_val), axis=2)\n    \n    X_test = rocket.transform(X_test)\n    X_test = np.expand_dims(np.array(X_test), axis=2)\n    \n    return X_train, X_val, X_test","metadata":{"execution":{"iopub.status.busy":"2022-05-22T01:28:32.387826Z","iopub.execute_input":"2022-05-22T01:28:32.389285Z","iopub.status.idle":"2022-05-22T01:28:32.396140Z","shell.execute_reply.started":"2022-05-22T01:28:32.389243Z","shell.execute_reply":"2022-05-22T01:28:32.395115Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def normalization(X_train, X_val, X_test):\n    scaler = StandardScaler()\n    shp = X_train.shape[1]\n    X_train = np.reshape(X_train, (-1,shp))\n    X_val = np.reshape(X_val, (-1,shp))\n    X_test = np.reshape(X_test, (-1,shp))\n    \n    X_train = scaler.fit_transform(X_train)\n    X_val = scaler.transform(X_val)\n    X_test = scaler.transform(X_test)\n    \n    return np.reshape(X_train, (-1,shp,1)), np.reshape(X_val, (-1,shp,1)), np.reshape(X_test, (-1,shp,1))","metadata":{"execution":{"iopub.status.busy":"2022-05-22T01:28:32.397575Z","iopub.execute_input":"2022-05-22T01:28:32.398845Z","iopub.status.idle":"2022-05-22T01:28:32.407914Z","shell.execute_reply.started":"2022-05-22T01:28:32.398803Z","shell.execute_reply":"2022-05-22T01:28:32.406956Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def timeseries_transform(data, head_size, num_heads, ff_dim, dropout=0):\n    \"\"\"\n    Implement the timeseries transformer here\n    \"\"\"\n    # Normalization and Attention\n    x = data\n    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n    x = layers.LayerNormalization(epsilon=1e-6)(x)\n    x = layers.Dropout(dropout)(x)\n    res = x + data\n\n    # Feed Forward Part\n    x = layers.LayerNormalization(epsilon=1e-6)(res)\n    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n    x = layers.Dropout(dropout)(x)\n    x = layers.Conv1D(filters=data.shape[-1], kernel_size=1)(x)\n    return x + res","metadata":{"execution":{"iopub.status.busy":"2022-05-22T01:28:32.409320Z","iopub.execute_input":"2022-05-22T01:28:32.409793Z","iopub.status.idle":"2022-05-22T01:28:32.420347Z","shell.execute_reply.started":"2022-05-22T01:28:32.409755Z","shell.execute_reply":"2022-05-22T01:28:32.419590Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def build_model(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout=0, mlp_dropout=0):\n    inputs = keras.Input(shape=input_shape)\n    x = inputs\n    for _ in range(num_transformer_blocks):\n        x = timeseries_transform(x, head_size, num_heads, ff_dim, dropout)\n\n    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n    for dim in mlp_units:\n        x = layers.Dense(dim, activation=\"relu\")(x)\n        x = layers.Dropout(mlp_dropout)(x)\n    outputs = layers.Dense(2, activation=\"sigmoid\")(x)\n    return keras.Model(inputs, outputs)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T01:28:32.423246Z","iopub.execute_input":"2022-05-22T01:28:32.423740Z","iopub.status.idle":"2022-05-22T01:28:32.431631Z","shell.execute_reply.started":"2022-05-22T01:28:32.423699Z","shell.execute_reply":"2022-05-22T01:28:32.430811Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def model_training(X_train, y_train, X_val, y_val):\n    \"\"\"\n    Train the data with the compatible model\n    \"\"\"\n    \n    input_shape = X_train.shape[1:]\n\n    model = build_model(input_shape, head_size=256, num_heads=4, ff_dim=4, num_transformer_blocks=4, mlp_units=[256], mlp_dropout=0.4, dropout=0.35)\n    lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-4, decay_steps=10000, decay_rate=0.9)\n\n    model.compile(\n        loss=\"sparse_categorical_crossentropy\",\n        optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n        metrics=[\"sparse_categorical_accuracy\"],\n    )\n    \n    model.summary()\n\n    callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n\n    model.fit(X_train, y_train, validation_data=(X_val,y_val),  epochs=200, batch_size=128, callbacks=callbacks)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-22T01:28:32.434511Z","iopub.execute_input":"2022-05-22T01:28:32.435216Z","iopub.status.idle":"2022-05-22T01:28:32.443902Z","shell.execute_reply.started":"2022-05-22T01:28:32.435175Z","shell.execute_reply":"2022-05-22T01:28:32.443127Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"def metric(y_act, y_pred):\n    \"\"\"\n    Standard metrics and plotting should be same\n    Metrics should be computed on validation data(unseen data)\n    1. Balanced accuracy score\n    2. Confusion matrix\n    3. Per-class accuracy\n    \"\"\"\n    \n    cm = metrics.confusion_matrix(y_act, y_pred)\n    balanced_accuracy = metrics.balanced_accuracy_score(y_act, y_pred)\n    \n    return cm, balanced_accuracy","metadata":{"execution":{"iopub.status.busy":"2022-05-22T01:28:32.447362Z","iopub.execute_input":"2022-05-22T01:28:32.447807Z","iopub.status.idle":"2022-05-22T01:28:32.455900Z","shell.execute_reply.started":"2022-05-22T01:28:32.447755Z","shell.execute_reply":"2022-05-22T01:28:32.455098Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def validation(X_val, y_val, metrics):\n    \"\"\"\n    Comparing the results with provided Series Embedder\n    Plot confusion matrices of self analysis and LSTM with balanced_accuracy\n    \n    \"\"\"\n    \n    score = model.evaluate(X_val, y_val, verbose=1)\n    \n    return score","metadata":{"execution":{"iopub.status.busy":"2022-05-22T01:28:32.459489Z","iopub.execute_input":"2022-05-22T01:28:32.459989Z","iopub.status.idle":"2022-05-22T01:28:32.466712Z","shell.execute_reply.started":"2022-05-22T01:28:32.459934Z","shell.execute_reply":"2022-05-22T01:28:32.465924Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def evaluate(X_test, y_act, metric, model):\n    y_pred = model.predict(X_test, verbose=1)\n    y_pred = np.argmax(y_pred, axis=1)\n    cm, ba = metric(y_act, y_pred)\n    \n    return y_pred, cm, ba","metadata":{"execution":{"iopub.status.busy":"2022-05-22T01:28:32.468263Z","iopub.execute_input":"2022-05-22T01:28:32.468845Z","iopub.status.idle":"2022-05-22T01:28:32.475752Z","shell.execute_reply.started":"2022-05-22T01:28:32.468803Z","shell.execute_reply":"2022-05-22T01:28:32.475007Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"path = \"../input/fordadata/data.pkl\"\ndata = load_data(path)\nX, y = preprocess_data(data)\nX = Rocket_preprocessing(X)\n\nX_train, X_val, X_test, y_train, y_val, y_test = split_train_test(X, y)\nX_train, X_val, X_test = Rocket(X_train, X_val, X_test)\nX_train, X_val, X_test = normalization(X_train, X_val, X_test)\nmodel_self=model_training(X_train, y_train, X_val, y_val)\n\nevaluate(X_test, y_test, metric, model_self)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T01:28:32.477290Z","iopub.execute_input":"2022-05-22T01:28:32.477607Z","iopub.status.idle":"2022-05-22T01:29:06.101834Z","shell.execute_reply.started":"2022-05-22T01:28:32.477571Z","shell.execute_reply":"2022-05-22T01:29:06.100329Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"(4921, 500)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_67/1048619415.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_train_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRocket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel_self\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_67/1776582576.py\u001b[0m in \u001b[0;36mRocket\u001b[0;34m(X_train, X_val, X_test)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mRocket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mrocket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMiniRocket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_kernels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# by default, ROCKET uses 10,000 kernels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sktime/transformations/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;31m# Non-optimized default implementation; override when a better\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;31m# method is possible for a given algorithm.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sktime/transformations/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;31m# input check and conversion for X/y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mX_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVectorizedDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sktime/transformations/base.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[0;34m(self, X, y, return_metadata)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# checking X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         X_valid, _, X_metadata = check_is_scitype(\n\u001b[0;32m--> 643\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscitype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mALLOWED_SCITYPES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m         )\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sktime/datatypes/_check.py\u001b[0m in \u001b[0;36mcheck_is_scitype\u001b[0;34m(obj, scitype, return_metadata, var_name, exclude_mtypes)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_metadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sktime/datatypes/_panel/_check.py\u001b[0m in \u001b[0;36mis_nested_dataframe\u001b[0;34m(obj, return_metadata, var_name)\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"is_one_series\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_nans\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nested_dataframe_has_nans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"is_equal_length\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_nested_dataframe_has_unequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sktime/datatypes/_panel/_check.py\u001b[0m in \u001b[0;36m_nested_dataframe_has_nans\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"model_self.save(\"transformer_banana_muffin_normalized\")\n!zip -r transformer_normalized.zip \"/kaggle/working/transformer_banana_muffin_normalized\nmodel_self.save(\"transformer_banana_muffin_normalized.h5\")\n!zip -r transformer_normalized.zip \"/kaggle/working/transformer_banana_muffin_normalized\"","metadata":{"execution":{"iopub.status.busy":"2022-05-22T01:29:06.103112Z","iopub.status.idle":"2022-05-22T01:29:06.103632Z","shell.execute_reply.started":"2022-05-22T01:29:06.103375Z","shell.execute_reply":"2022-05-22T01:29:06.103402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# metrics=metric(val,model_self)\n\n# lstm_cm,lstm_balanced_accuracy=lstm(preprocessed_data,target='labels')\n# metrics_validation = [lstm_cm, lstm_balanced_accuracy]\n# validation(metrics,metrics_validation)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T01:29:06.105627Z","iopub.status.idle":"2022-05-22T01:29:06.106123Z","shell.execute_reply.started":"2022-05-22T01:29:06.105849Z","shell.execute_reply":"2022-05-22T01:29:06.105875Z"},"trusted":true},"execution_count":null,"outputs":[]}]}