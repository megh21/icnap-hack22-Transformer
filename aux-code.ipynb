{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sktime","metadata":{"execution":{"iopub.status.busy":"2022-05-22T00:48:29.780056Z","iopub.execute_input":"2022-05-22T00:48:29.780435Z","iopub.status.idle":"2022-05-22T00:48:45.472898Z","shell.execute_reply.started":"2022-05-22T00:48:29.780338Z","shell.execute_reply":"2022-05-22T00:48:45.471958Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting sktime\n  Downloading sktime-0.11.4-py3-none-any.whl (6.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n\u001b[?25hRequirement already satisfied: scipy<1.9.0 in /opt/conda/lib/python3.7/site-packages (from sktime) (1.7.3)\nRequirement already satisfied: pandas<1.5.0,>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from sktime) (1.3.5)\nRequirement already satisfied: statsmodels>=0.12.1 in /opt/conda/lib/python3.7/site-packages (from sktime) (0.13.2)\nCollecting deprecated>=1.2.13\n  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\nRequirement already satisfied: numba>=0.53 in /opt/conda/lib/python3.7/site-packages (from sktime) (0.55.1)\nRequirement already satisfied: numpy<1.22,>=1.21.0 in /opt/conda/lib/python3.7/site-packages (from sktime) (1.21.6)\nRequirement already satisfied: scikit-learn<1.2.0,>=0.24.0 in /opt/conda/lib/python3.7/site-packages (from sktime) (1.0.2)\nRequirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from deprecated>=1.2.13->sktime) (1.14.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba>=0.53->sktime) (59.8.0)\nRequirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /opt/conda/lib/python3.7/site-packages (from numba>=0.53->sktime) (0.38.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas<1.5.0,>=1.1.0->sktime) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas<1.5.0,>=1.1.0->sktime) (2021.3)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn<1.2.0,>=0.24.0->sktime) (1.0.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn<1.2.0,>=0.24.0->sktime) (3.1.0)\nRequirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.7/site-packages (from statsmodels>=0.12.1->sktime) (21.3)\nRequirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.7/site-packages (from statsmodels>=0.12.1->sktime) (0.5.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=21.3->statsmodels>=0.12.1->sktime) (3.0.7)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from patsy>=0.5.2->statsmodels>=0.12.1->sktime) (1.16.0)\nInstalling collected packages: deprecated, sktime\nSuccessfully installed deprecated-1.2.13 sktime-0.11.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"\nHackathon - INCAP - IconPro GmbH\nTimeseries Classification with Transformers\n\"\"\"\nimport pandas as pd\nfrom tensorflow import keras\nfrom dataclasses import dataclass\nfrom tensorflow.keras import layers\nimport os\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import metrics\nfrom sklearn.linear_model import RidgeClassifierCV\nfrom sklearn.pipeline import make_pipeline\nfrom sktime.transformations.panel.rocket import Rocket, MiniRocket\n# Import packages as you need","metadata":{"execution":{"iopub.status.busy":"2022-05-22T00:48:45.475185Z","iopub.execute_input":"2022-05-22T00:48:45.475470Z","iopub.status.idle":"2022-05-22T00:51:53.107922Z","shell.execute_reply.started":"2022-05-22T00:48:45.475432Z","shell.execute_reply":"2022-05-22T00:51:53.107106Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def load_data(data_path):\n    \"\"\"\n    Loading of the dataset provided\n    Edit the code below\n    \"\"\"\n    data = pd.read_pickle(data_path)\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-05-22T00:51:53.109510Z","iopub.execute_input":"2022-05-22T00:51:53.109822Z","iopub.status.idle":"2022-05-22T00:51:53.114681Z","shell.execute_reply.started":"2022-05-22T00:51:53.109772Z","shell.execute_reply":"2022-05-22T00:51:53.113839Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def preprocess_data(data):\n    \"\"\"\n    A standard nan removal to be added.\n    Add more preprocessing steps if needed.\n    \"\"\"\n    \n    X = data['dim_0'].apply(lambda x: x.reshape(500,1))\n    \n    for i in range(data.shape[0]):\n        if True in np.isnan(data['dim_0'][i]).flatten():\n            print(i)\n            \n    input_x = []\n    for array in X:\n        input_x.append(array)\n    \n#     X = pd.DataFrame(data.dim_0.tolist())\n#     X = X.to_numpy()\n    \n    y = data['labels']\n    y = y.astype(int)\n    y[y == -1] = 0\n    return input_x,y","metadata":{"execution":{"iopub.status.busy":"2022-05-22T00:51:53.117300Z","iopub.execute_input":"2022-05-22T00:51:53.117603Z","iopub.status.idle":"2022-05-22T00:51:53.126523Z","shell.execute_reply.started":"2022-05-22T00:51:53.117564Z","shell.execute_reply":"2022-05-22T00:51:53.125526Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def Rocket_preprocessing(input_x):\n    input_x1=[]\n    input_x = np.array(input_x).reshape(4921, 500)\n    print(input_x.shape)\n    for i in range(input_x.shape[0]):\n        input_x1.append(pd.Series(input_x[i]))\n    input_x1=pd.Series(input_x1)\n#    input_x1.shape\n    \n    input_x1=pd.DataFrame(input_x1)\n    return input_x1","metadata":{"execution":{"iopub.status.busy":"2022-05-22T00:51:53.127772Z","iopub.execute_input":"2022-05-22T00:51:53.128323Z","iopub.status.idle":"2022-05-22T00:51:53.135825Z","shell.execute_reply.started":"2022-05-22T00:51:53.128282Z","shell.execute_reply":"2022-05-22T00:51:53.134910Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def split_train_test(X, y):\n    \"\"\"\n    Splitting the data into train, test, validation \n    \"\"\"\n    \n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n    \n    return X_train, X_val, X_test, y_train, y_val, y_test","metadata":{"execution":{"iopub.status.busy":"2022-05-22T00:51:53.137196Z","iopub.execute_input":"2022-05-22T00:51:53.137672Z","iopub.status.idle":"2022-05-22T00:51:53.145140Z","shell.execute_reply.started":"2022-05-22T00:51:53.137631Z","shell.execute_reply":"2022-05-22T00:51:53.144193Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def Rocket(X_train, X_val, X_test):\n    rocket = MiniRocket(num_kernels=500)  # by default, ROCKET uses 10,000 kernels\n    X_train = rocket.fit_transform(X_train)\n    X_train = np.expand_dims(np.array(X_train), axis=2)\n    \n    X_val = rocket.transform(X_val)\n    X_val = np.expand_dims(np.array(X_val), axis=2)\n    \n    X_test = rocket.transform(X_test)\n    X_test = np.expand_dims(np.array(X_test), axis=2)\n    \n    return X_train, X_val, X_test","metadata":{"execution":{"iopub.status.busy":"2022-05-22T00:51:53.146548Z","iopub.execute_input":"2022-05-22T00:51:53.147131Z","iopub.status.idle":"2022-05-22T00:51:53.155933Z","shell.execute_reply.started":"2022-05-22T00:51:53.147086Z","shell.execute_reply":"2022-05-22T00:51:53.155111Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def normalization(X_train, X_val, X_test):\n    scaler = StandardScaler()\n    shp = X_train.shape[1]\n    X_train = np.reshape(X_train, (-1,shp))\n    X_val = np.reshape(X_val, (-1,shp))\n    X_test = np.reshape(X_test, (-1,shp))\n    \n    X_train = scaler.fit_transform(X_train)\n    X_val = scaler.transform(X_val)\n    X_test = scaler.transform(X_test)\n    \n    return np.reshape(X_train, (-1,shp,1)), np.reshape(X_val, (-1,shp,1)), np.reshape(X_test, (-1,shp,1))","metadata":{"execution":{"iopub.status.busy":"2022-05-22T00:51:53.156969Z","iopub.execute_input":"2022-05-22T00:51:53.157543Z","iopub.status.idle":"2022-05-22T00:51:53.168958Z","shell.execute_reply.started":"2022-05-22T00:51:53.157502Z","shell.execute_reply":"2022-05-22T00:51:53.168164Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def timeseries_transform(data, head_size, num_heads, ff_dim, dropout=0):\n    \"\"\"\n    Implement the timeseries transformer here\n    \"\"\"\n    # Normalization and Attention\n    x = data\n    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n    x = layers.LayerNormalization(epsilon=1e-6)(x)\n    x = layers.Dropout(dropout)(x)\n    res = x + data\n\n    # Feed Forward Part\n    x = layers.LayerNormalization(epsilon=1e-6)(res)\n    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n    x = layers.Dropout(dropout)(x)\n    x = layers.Conv1D(filters=data.shape[-1], kernel_size=1)(x)\n    return x + res","metadata":{"execution":{"iopub.status.busy":"2022-05-22T00:51:53.170584Z","iopub.execute_input":"2022-05-22T00:51:53.171118Z","iopub.status.idle":"2022-05-22T00:51:53.179570Z","shell.execute_reply.started":"2022-05-22T00:51:53.171064Z","shell.execute_reply":"2022-05-22T00:51:53.178809Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def build_model(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout=0, mlp_dropout=0):\n    inputs = keras.Input(shape=input_shape)\n    x = inputs\n    for _ in range(num_transformer_blocks):\n        x = timeseries_transform(x, head_size, num_heads, ff_dim, dropout)\n\n    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n    for dim in mlp_units:\n        x = layers.Dense(dim, activation=\"relu\")(x)\n        x = layers.Dropout(mlp_dropout)(x)\n    outputs = layers.Dense(2, activation=\"sigmoid\")(x)\n    return keras.Model(inputs, outputs)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T00:51:53.182764Z","iopub.execute_input":"2022-05-22T00:51:53.183368Z","iopub.status.idle":"2022-05-22T00:51:53.192585Z","shell.execute_reply.started":"2022-05-22T00:51:53.183327Z","shell.execute_reply":"2022-05-22T00:51:53.191753Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def model_training(X_train, y_train, X_val, y_val):\n    \"\"\"\n    Train the data with the compatible model\n    \"\"\"\n    \n    input_shape = X_train.shape[1:]\n\n    model = build_model(input_shape, head_size=256, num_heads=4, ff_dim=4, num_transformer_blocks=4, mlp_units=[256], mlp_dropout=0.4, dropout=0.25)\n    lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-4, decay_steps=10000, decay_rate=0.9)\n\n    model.compile(\n        loss=\"sparse_categorical_crossentropy\",\n        optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n        metrics=[\"sparse_categorical_accuracy\"],\n    )\n    \n    model.summary()\n\n    callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n\n    model.fit(X_train, y_train, validation_data=(X_val,y_val),  epochs=200, batch_size=128, callbacks=callbacks)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-22T00:51:53.193903Z","iopub.execute_input":"2022-05-22T00:51:53.194224Z","iopub.status.idle":"2022-05-22T00:51:53.205142Z","shell.execute_reply.started":"2022-05-22T00:51:53.194186Z","shell.execute_reply":"2022-05-22T00:51:53.204469Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def metric(y_act, y_pred):\n    \"\"\"\n    Standard metrics and plotting should be same\n    Metrics should be computed on validation data(unseen data)\n    1. Balanced accuracy score\n    2. Confusion matrix\n    3. Per-class accuracy\n    \"\"\"\n    \n    cm = metrics.confusion_matrix(y_act, y_pred)\n    balanced_accuracy = metrics.balanced_accuracy_score(y_act, y_pred)\n    \n    return cm, balanced_accuracy","metadata":{"execution":{"iopub.status.busy":"2022-05-22T00:51:53.206387Z","iopub.execute_input":"2022-05-22T00:51:53.206882Z","iopub.status.idle":"2022-05-22T00:51:53.214322Z","shell.execute_reply.started":"2022-05-22T00:51:53.206845Z","shell.execute_reply":"2022-05-22T00:51:53.213312Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def validation(X_val, y_val, metrics):\n    \"\"\"\n    Comparing the results with provided Series Embedder\n    Plot confusion matrices of self analysis and LSTM with balanced_accuracy\n    \n    \"\"\"\n    \n    score = model.evaluate(X_val, y_val, verbose=1)\n    \n    return score","metadata":{"execution":{"iopub.status.busy":"2022-05-22T00:51:53.215899Z","iopub.execute_input":"2022-05-22T00:51:53.216463Z","iopub.status.idle":"2022-05-22T00:51:53.223690Z","shell.execute_reply.started":"2022-05-22T00:51:53.216421Z","shell.execute_reply":"2022-05-22T00:51:53.222830Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def evaluate(X_test, y_act, metric, model):\n    y_pred = model.predict(X_test, verbose=1)\n    y_pred = np.argmax(y_pred, axis=1)\n    cm, ba = metric(y_act, y_pred)\n    \n    return y_pred, cm, ba","metadata":{"execution":{"iopub.status.busy":"2022-05-22T00:51:53.224594Z","iopub.execute_input":"2022-05-22T00:51:53.227082Z","iopub.status.idle":"2022-05-22T00:51:53.235249Z","shell.execute_reply.started":"2022-05-22T00:51:53.227021Z","shell.execute_reply":"2022-05-22T00:51:53.234521Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"path = \"../input/fordadata/data.pkl\"\ndata = load_data(path)\nX, y = preprocess_data(data)\nX = Rocket_preprocessing(X)\n\nX_train, X_val, X_test, y_train, y_val, y_test = split_train_test(X, y)\nX_train, X_val, X_test = Rocket(X_train, X_val, X_test)\nX_train, X_val, X_test = normalization(X_train, X_val, X_test)\nmodel_self=model_training(X_train, y_train, X_val, y_val)\n\nevaluate(X_test, y_test, metric, model_self)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T00:51:53.236448Z","iopub.execute_input":"2022-05-22T00:51:53.236802Z","iopub.status.idle":"2022-05-22T01:04:43.032033Z","shell.execute_reply.started":"2022-05-22T00:51:53.236754Z","shell.execute_reply":"2022-05-22T01:04:43.031314Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"(4921, 500)\n(3148, 420, 1)\n(985, 420, 1)\n(788, 420, 1)\n","output_type":"stream"},{"name":"stderr","text":"2022-05-22 00:53:13.624607: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-05-22 00:53:13.725845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-05-22 00:53:13.726704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-05-22 00:53:13.728731: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-05-22 00:53:13.729122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-05-22 00:53:13.729856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-05-22 00:53:13.730561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-05-22 00:53:15.828627: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-05-22 00:53:15.829847: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-05-22 00:53:15.830847: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-05-22 00:53:15.832548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 420, 1)]     0                                            \n__________________________________________________________________________________________________\nmulti_head_attention (MultiHead (None, 420, 1)       7169        input_1[0][0]                    \n                                                                 input_1[0][0]                    \n__________________________________________________________________________________________________\nlayer_normalization (LayerNorma (None, 420, 1)       2           multi_head_attention[0][0]       \n__________________________________________________________________________________________________\ndropout (Dropout)               (None, 420, 1)       0           layer_normalization[0][0]        \n__________________________________________________________________________________________________\ntf.__operators__.add (TFOpLambd (None, 420, 1)       0           dropout[0][0]                    \n                                                                 input_1[0][0]                    \n__________________________________________________________________________________________________\nlayer_normalization_1 (LayerNor (None, 420, 1)       2           tf.__operators__.add[0][0]       \n__________________________________________________________________________________________________\nconv1d (Conv1D)                 (None, 420, 4)       8           layer_normalization_1[0][0]      \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 420, 4)       0           conv1d[0][0]                     \n__________________________________________________________________________________________________\nconv1d_1 (Conv1D)               (None, 420, 1)       5           dropout_1[0][0]                  \n__________________________________________________________________________________________________\ntf.__operators__.add_1 (TFOpLam (None, 420, 1)       0           conv1d_1[0][0]                   \n                                                                 tf.__operators__.add[0][0]       \n__________________________________________________________________________________________________\nmulti_head_attention_1 (MultiHe (None, 420, 1)       7169        tf.__operators__.add_1[0][0]     \n                                                                 tf.__operators__.add_1[0][0]     \n__________________________________________________________________________________________________\nlayer_normalization_2 (LayerNor (None, 420, 1)       2           multi_head_attention_1[0][0]     \n__________________________________________________________________________________________________\ndropout_2 (Dropout)             (None, 420, 1)       0           layer_normalization_2[0][0]      \n__________________________________________________________________________________________________\ntf.__operators__.add_2 (TFOpLam (None, 420, 1)       0           dropout_2[0][0]                  \n                                                                 tf.__operators__.add_1[0][0]     \n__________________________________________________________________________________________________\nlayer_normalization_3 (LayerNor (None, 420, 1)       2           tf.__operators__.add_2[0][0]     \n__________________________________________________________________________________________________\nconv1d_2 (Conv1D)               (None, 420, 4)       8           layer_normalization_3[0][0]      \n__________________________________________________________________________________________________\ndropout_3 (Dropout)             (None, 420, 4)       0           conv1d_2[0][0]                   \n__________________________________________________________________________________________________\nconv1d_3 (Conv1D)               (None, 420, 1)       5           dropout_3[0][0]                  \n__________________________________________________________________________________________________\ntf.__operators__.add_3 (TFOpLam (None, 420, 1)       0           conv1d_3[0][0]                   \n                                                                 tf.__operators__.add_2[0][0]     \n__________________________________________________________________________________________________\nmulti_head_attention_2 (MultiHe (None, 420, 1)       7169        tf.__operators__.add_3[0][0]     \n                                                                 tf.__operators__.add_3[0][0]     \n__________________________________________________________________________________________________\nlayer_normalization_4 (LayerNor (None, 420, 1)       2           multi_head_attention_2[0][0]     \n__________________________________________________________________________________________________\ndropout_4 (Dropout)             (None, 420, 1)       0           layer_normalization_4[0][0]      \n__________________________________________________________________________________________________\ntf.__operators__.add_4 (TFOpLam (None, 420, 1)       0           dropout_4[0][0]                  \n                                                                 tf.__operators__.add_3[0][0]     \n__________________________________________________________________________________________________\nlayer_normalization_5 (LayerNor (None, 420, 1)       2           tf.__operators__.add_4[0][0]     \n__________________________________________________________________________________________________\nconv1d_4 (Conv1D)               (None, 420, 4)       8           layer_normalization_5[0][0]      \n__________________________________________________________________________________________________\ndropout_5 (Dropout)             (None, 420, 4)       0           conv1d_4[0][0]                   \n__________________________________________________________________________________________________\nconv1d_5 (Conv1D)               (None, 420, 1)       5           dropout_5[0][0]                  \n__________________________________________________________________________________________________\ntf.__operators__.add_5 (TFOpLam (None, 420, 1)       0           conv1d_5[0][0]                   \n                                                                 tf.__operators__.add_4[0][0]     \n__________________________________________________________________________________________________\nmulti_head_attention_3 (MultiHe (None, 420, 1)       7169        tf.__operators__.add_5[0][0]     \n                                                                 tf.__operators__.add_5[0][0]     \n__________________________________________________________________________________________________\nlayer_normalization_6 (LayerNor (None, 420, 1)       2           multi_head_attention_3[0][0]     \n__________________________________________________________________________________________________\ndropout_6 (Dropout)             (None, 420, 1)       0           layer_normalization_6[0][0]      \n__________________________________________________________________________________________________\ntf.__operators__.add_6 (TFOpLam (None, 420, 1)       0           dropout_6[0][0]                  \n                                                                 tf.__operators__.add_5[0][0]     \n__________________________________________________________________________________________________\nlayer_normalization_7 (LayerNor (None, 420, 1)       2           tf.__operators__.add_6[0][0]     \n__________________________________________________________________________________________________\nconv1d_6 (Conv1D)               (None, 420, 4)       8           layer_normalization_7[0][0]      \n__________________________________________________________________________________________________\ndropout_7 (Dropout)             (None, 420, 4)       0           conv1d_6[0][0]                   \n__________________________________________________________________________________________________\nconv1d_7 (Conv1D)               (None, 420, 1)       5           dropout_7[0][0]                  \n__________________________________________________________________________________________________\ntf.__operators__.add_7 (TFOpLam (None, 420, 1)       0           conv1d_7[0][0]                   \n                                                                 tf.__operators__.add_6[0][0]     \n__________________________________________________________________________________________________\nglobal_average_pooling1d (Globa (None, 420)          0           tf.__operators__.add_7[0][0]     \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 256)          107776      global_average_pooling1d[0][0]   \n__________________________________________________________________________________________________\ndropout_8 (Dropout)             (None, 256)          0           dense[0][0]                      \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 2)            514         dropout_8[0][0]                  \n==================================================================================================\nTotal params: 137,034\nTrainable params: 137,034\nNon-trainable params: 0\n__________________________________________________________________________________________________\nEpoch 1/200\n","output_type":"stream"},{"name":"stderr","text":"2022-05-22 00:53:16.668537: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n2022-05-22 00:53:21.396493: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"25/25 [==============================] - 21s 474ms/step - loss: 0.7092 - sparse_categorical_accuracy: 0.6401 - val_loss: 0.4160 - val_sparse_categorical_accuracy: 0.8173\nEpoch 2/200\n25/25 [==============================] - 11s 457ms/step - loss: 0.4566 - sparse_categorical_accuracy: 0.7986 - val_loss: 0.3077 - val_sparse_categorical_accuracy: 0.8670\nEpoch 3/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.3633 - sparse_categorical_accuracy: 0.8386 - val_loss: 0.2627 - val_sparse_categorical_accuracy: 0.8914\nEpoch 4/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.3145 - sparse_categorical_accuracy: 0.8659 - val_loss: 0.2372 - val_sparse_categorical_accuracy: 0.9015\nEpoch 5/200\n25/25 [==============================] - 11s 456ms/step - loss: 0.2793 - sparse_categorical_accuracy: 0.8904 - val_loss: 0.2234 - val_sparse_categorical_accuracy: 0.9086\nEpoch 6/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.2613 - sparse_categorical_accuracy: 0.8910 - val_loss: 0.2112 - val_sparse_categorical_accuracy: 0.9117\nEpoch 7/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.2489 - sparse_categorical_accuracy: 0.9025 - val_loss: 0.2029 - val_sparse_categorical_accuracy: 0.9147\nEpoch 8/200\n25/25 [==============================] - 11s 456ms/step - loss: 0.2320 - sparse_categorical_accuracy: 0.9047 - val_loss: 0.1963 - val_sparse_categorical_accuracy: 0.9198\nEpoch 9/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.2151 - sparse_categorical_accuracy: 0.9114 - val_loss: 0.1906 - val_sparse_categorical_accuracy: 0.9198\nEpoch 10/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.2108 - sparse_categorical_accuracy: 0.9145 - val_loss: 0.1869 - val_sparse_categorical_accuracy: 0.9228\nEpoch 11/200\n25/25 [==============================] - 11s 456ms/step - loss: 0.2052 - sparse_categorical_accuracy: 0.9158 - val_loss: 0.1851 - val_sparse_categorical_accuracy: 0.9269\nEpoch 12/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.1966 - sparse_categorical_accuracy: 0.9219 - val_loss: 0.1797 - val_sparse_categorical_accuracy: 0.9279\nEpoch 13/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.1858 - sparse_categorical_accuracy: 0.9257 - val_loss: 0.1766 - val_sparse_categorical_accuracy: 0.9279\nEpoch 14/200\n25/25 [==============================] - 11s 456ms/step - loss: 0.1807 - sparse_categorical_accuracy: 0.9298 - val_loss: 0.1756 - val_sparse_categorical_accuracy: 0.9320\nEpoch 15/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.1786 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.1719 - val_sparse_categorical_accuracy: 0.9320\nEpoch 16/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.1595 - sparse_categorical_accuracy: 0.9368 - val_loss: 0.1707 - val_sparse_categorical_accuracy: 0.9310\nEpoch 17/200\n25/25 [==============================] - 11s 456ms/step - loss: 0.1579 - sparse_categorical_accuracy: 0.9349 - val_loss: 0.1687 - val_sparse_categorical_accuracy: 0.9320\nEpoch 18/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.1650 - sparse_categorical_accuracy: 0.9358 - val_loss: 0.1656 - val_sparse_categorical_accuracy: 0.9330\nEpoch 19/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.1556 - sparse_categorical_accuracy: 0.9358 - val_loss: 0.1646 - val_sparse_categorical_accuracy: 0.9371\nEpoch 20/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.1472 - sparse_categorical_accuracy: 0.9406 - val_loss: 0.1643 - val_sparse_categorical_accuracy: 0.9340\nEpoch 21/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.1460 - sparse_categorical_accuracy: 0.9450 - val_loss: 0.1639 - val_sparse_categorical_accuracy: 0.9330\nEpoch 22/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.1424 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.1620 - val_sparse_categorical_accuracy: 0.9350\nEpoch 23/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.1371 - sparse_categorical_accuracy: 0.9460 - val_loss: 0.1611 - val_sparse_categorical_accuracy: 0.9381\nEpoch 24/200\n25/25 [==============================] - 11s 454ms/step - loss: 0.1426 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.1612 - val_sparse_categorical_accuracy: 0.9340\nEpoch 25/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.1304 - sparse_categorical_accuracy: 0.9492 - val_loss: 0.1598 - val_sparse_categorical_accuracy: 0.9371\nEpoch 26/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.1233 - sparse_categorical_accuracy: 0.9504 - val_loss: 0.1589 - val_sparse_categorical_accuracy: 0.9350\nEpoch 27/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.1305 - sparse_categorical_accuracy: 0.9508 - val_loss: 0.1594 - val_sparse_categorical_accuracy: 0.9340\nEpoch 28/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.1264 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1570 - val_sparse_categorical_accuracy: 0.9371\nEpoch 29/200\n25/25 [==============================] - 11s 456ms/step - loss: 0.1192 - sparse_categorical_accuracy: 0.9530 - val_loss: 0.1564 - val_sparse_categorical_accuracy: 0.9360\nEpoch 30/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.1192 - sparse_categorical_accuracy: 0.9514 - val_loss: 0.1551 - val_sparse_categorical_accuracy: 0.9371\nEpoch 31/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.1092 - sparse_categorical_accuracy: 0.9600 - val_loss: 0.1556 - val_sparse_categorical_accuracy: 0.9381\nEpoch 32/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.1115 - sparse_categorical_accuracy: 0.9549 - val_loss: 0.1538 - val_sparse_categorical_accuracy: 0.9360\nEpoch 33/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.1112 - sparse_categorical_accuracy: 0.9571 - val_loss: 0.1535 - val_sparse_categorical_accuracy: 0.9391\nEpoch 34/200\n25/25 [==============================] - 11s 457ms/step - loss: 0.1110 - sparse_categorical_accuracy: 0.9600 - val_loss: 0.1526 - val_sparse_categorical_accuracy: 0.9371\nEpoch 35/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.1063 - sparse_categorical_accuracy: 0.9590 - val_loss: 0.1545 - val_sparse_categorical_accuracy: 0.9381\nEpoch 36/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.1059 - sparse_categorical_accuracy: 0.9593 - val_loss: 0.1527 - val_sparse_categorical_accuracy: 0.9391\nEpoch 37/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.0975 - sparse_categorical_accuracy: 0.9654 - val_loss: 0.1562 - val_sparse_categorical_accuracy: 0.9360\nEpoch 38/200\n25/25 [==============================] - 11s 454ms/step - loss: 0.0993 - sparse_categorical_accuracy: 0.9641 - val_loss: 0.1533 - val_sparse_categorical_accuracy: 0.9381\nEpoch 39/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.0991 - sparse_categorical_accuracy: 0.9641 - val_loss: 0.1540 - val_sparse_categorical_accuracy: 0.9391\nEpoch 40/200\n25/25 [==============================] - 11s 456ms/step - loss: 0.0990 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1524 - val_sparse_categorical_accuracy: 0.9391\nEpoch 41/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.0870 - sparse_categorical_accuracy: 0.9692 - val_loss: 0.1520 - val_sparse_categorical_accuracy: 0.9401\nEpoch 42/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.0929 - sparse_categorical_accuracy: 0.9679 - val_loss: 0.1507 - val_sparse_categorical_accuracy: 0.9411\nEpoch 43/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.0922 - sparse_categorical_accuracy: 0.9673 - val_loss: 0.1518 - val_sparse_categorical_accuracy: 0.9411\nEpoch 44/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.0888 - sparse_categorical_accuracy: 0.9692 - val_loss: 0.1521 - val_sparse_categorical_accuracy: 0.9411\nEpoch 45/200\n25/25 [==============================] - 11s 454ms/step - loss: 0.0903 - sparse_categorical_accuracy: 0.9657 - val_loss: 0.1488 - val_sparse_categorical_accuracy: 0.9421\nEpoch 46/200\n25/25 [==============================] - 11s 456ms/step - loss: 0.0835 - sparse_categorical_accuracy: 0.9717 - val_loss: 0.1527 - val_sparse_categorical_accuracy: 0.9411\nEpoch 47/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.0849 - sparse_categorical_accuracy: 0.9679 - val_loss: 0.1500 - val_sparse_categorical_accuracy: 0.9411\nEpoch 48/200\n25/25 [==============================] - 11s 454ms/step - loss: 0.0861 - sparse_categorical_accuracy: 0.9673 - val_loss: 0.1502 - val_sparse_categorical_accuracy: 0.9411\nEpoch 49/200\n25/25 [==============================] - 11s 456ms/step - loss: 0.0863 - sparse_categorical_accuracy: 0.9711 - val_loss: 0.1522 - val_sparse_categorical_accuracy: 0.9401\nEpoch 50/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.0783 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.1501 - val_sparse_categorical_accuracy: 0.9411\nEpoch 51/200\n25/25 [==============================] - 11s 454ms/step - loss: 0.0775 - sparse_categorical_accuracy: 0.9730 - val_loss: 0.1535 - val_sparse_categorical_accuracy: 0.9411\nEpoch 52/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.0761 - sparse_categorical_accuracy: 0.9733 - val_loss: 0.1521 - val_sparse_categorical_accuracy: 0.9431\nEpoch 53/200\n25/25 [==============================] - 11s 454ms/step - loss: 0.0755 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.1516 - val_sparse_categorical_accuracy: 0.9401\nEpoch 54/200\n25/25 [==============================] - 11s 454ms/step - loss: 0.0749 - sparse_categorical_accuracy: 0.9733 - val_loss: 0.1525 - val_sparse_categorical_accuracy: 0.9401\nEpoch 55/200\n25/25 [==============================] - 11s 455ms/step - loss: 0.0736 - sparse_categorical_accuracy: 0.9762 - val_loss: 0.1514 - val_sparse_categorical_accuracy: 0.9442\n25/25 [==============================] - 1s 38ms/step\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(array([1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n        1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n        1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n        0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n        0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n        1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n        1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n        0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n        0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n        0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n        1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n        1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n        1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n        0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n        0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n        0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n        1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n        1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n        0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n        1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n        0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n        1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n        0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n        1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n        1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n        1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n        0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n        1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n        1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n        1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n        1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n        0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n        1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n        1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n        1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n        1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1]),\n array([[383,  22],\n        [ 21, 362]]),\n 0.9454243625697063)"},"metadata":{}}]},{"cell_type":"code","source":"model_self.save(\"transformer_banana_muffin_normalized\")\n!zip -r transformer_normalized.zip \"/kaggle/working/transformer_banana_muffin_normalized\nmodel_self.save(\"transformer_banana_muffin_normalized.h5\")\n!zip -r transformer_normalized.zip \"/kaggle/working/transformer_banana_muffin_normalized\"","metadata":{"execution":{"iopub.status.busy":"2022-05-22T01:04:43.033312Z","iopub.execute_input":"2022-05-22T01:04:43.033638Z","iopub.status.idle":"2022-05-22T01:04:51.787726Z","shell.execute_reply.started":"2022-05-22T01:04:43.033601Z","shell.execute_reply":"2022-05-22T01:04:51.786845Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"2022-05-22 01:04:44.620657: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","output_type":"stream"},{"name":"stdout","text":"/bin/bash: -c: line 0: unexpected EOF while looking for matching `\"'\n/bin/bash: -c: line 1: syntax error: unexpected end of file\n  adding: kaggle/working/transformer_banana_muffin_normalized/ (stored 0%)\n  adding: kaggle/working/transformer_banana_muffin_normalized/assets/ (stored 0%)\n  adding: kaggle/working/transformer_banana_muffin_normalized/saved_model.pb (deflated 91%)\n  adding: kaggle/working/transformer_banana_muffin_normalized/keras_metadata.pb (deflated 95%)\n  adding: kaggle/working/transformer_banana_muffin_normalized/variables/ (stored 0%)\n  adding: kaggle/working/transformer_banana_muffin_normalized/variables/variables.data-00000-of-00001 (deflated 25%)\n  adding: kaggle/working/transformer_banana_muffin_normalized/variables/variables.index (deflated 84%)\n","output_type":"stream"}]},{"cell_type":"code","source":"# metrics=metric(val,model_self)\n\n# lstm_cm,lstm_balanced_accuracy=lstm(preprocessed_data,target='labels')\n# metrics_validation = [lstm_cm, lstm_balanced_accuracy]\n# validation(metrics,metrics_validation)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T01:04:51.789620Z","iopub.execute_input":"2022-05-22T01:04:51.790188Z","iopub.status.idle":"2022-05-22T01:04:51.794580Z","shell.execute_reply.started":"2022-05-22T01:04:51.790147Z","shell.execute_reply":"2022-05-22T01:04:51.793527Z"},"trusted":true},"execution_count":17,"outputs":[]}]}