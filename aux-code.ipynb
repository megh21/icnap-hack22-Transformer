{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nHackathon - INCAP - IconPro GmbH\nTimeseries Classification with Transformers\n\"\"\"\nimport pandas as pd\nfrom tensorflow import keras\nfrom dataclasses import dataclass\nfrom tensorflow.keras import layers\nimport os\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n# Import packages as you need","metadata":{"execution":{"iopub.status.busy":"2022-05-21T16:43:55.737820Z","iopub.execute_input":"2022-05-21T16:43:55.738074Z","iopub.status.idle":"2022-05-21T16:43:55.742790Z","shell.execute_reply.started":"2022-05-21T16:43:55.738046Z","shell.execute_reply":"2022-05-21T16:43:55.741935Z"},"trusted":true},"execution_count":321,"outputs":[]},{"cell_type":"code","source":"def load_data(data_path):\n    \"\"\"\n    Loading of the dataset provided\n    Edit the code below\n    \"\"\"\n    data = pd.read_pickle(data_path)\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-05-21T16:43:55.803894Z","iopub.execute_input":"2022-05-21T16:43:55.804199Z","iopub.status.idle":"2022-05-21T16:43:55.809666Z","shell.execute_reply.started":"2022-05-21T16:43:55.804169Z","shell.execute_reply":"2022-05-21T16:43:55.808992Z"},"trusted":true},"execution_count":322,"outputs":[]},{"cell_type":"code","source":"def preprocess_data(data):\n    \"\"\"\n    A standard nan removal to be added.\n    Add more preprocessing steps if needed.\n    \"\"\"\n    \n    X = data['dim_0'].apply(lambda x: x.reshape(500,1))\n    \n    for i in range(data.shape[0]):\n        if True in np.isnan(data['dim_0'][i]).flatten():\n            print(i)\n            \n    input_x = []\n    for array in X:\n        input_x.append(array)\n    \n#     X = pd.DataFrame(data.dim_0.tolist())\n#     X = X.to_numpy()\n    \n    y = data['labels']\n    y = y.astype(int)\n    y[y == -1] = 0\n    return input_x,y","metadata":{"execution":{"iopub.status.busy":"2022-05-21T16:43:55.914382Z","iopub.execute_input":"2022-05-21T16:43:55.914592Z","iopub.status.idle":"2022-05-21T16:43:55.920998Z","shell.execute_reply.started":"2022-05-21T16:43:55.914569Z","shell.execute_reply":"2022-05-21T16:43:55.920200Z"},"trusted":true},"execution_count":323,"outputs":[]},{"cell_type":"code","source":"def split_train_test(X, y):\n    \"\"\"\n    Splitting the data into train, test, validation \n    \"\"\"\n    \n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n    \n    return X_train, X_test, X_val, y_train, y_test, y_val","metadata":{"execution":{"iopub.status.busy":"2022-05-21T16:43:56.024817Z","iopub.execute_input":"2022-05-21T16:43:56.025391Z","iopub.status.idle":"2022-05-21T16:43:56.030635Z","shell.execute_reply.started":"2022-05-21T16:43:56.025337Z","shell.execute_reply":"2022-05-21T16:43:56.029762Z"},"trusted":true},"execution_count":324,"outputs":[]},{"cell_type":"code","source":"def normalization(X_train, X_test, X_val):\n    scaler = MinMaxScaler(feature_range=(0,1))\n    X_train = np.reshape(X_train, (-1,500))\n    X_val = np.reshape(X_val, (-1,500))\n    X_test = np.reshape(X_test, (-1,500))\n    \n    X_train = scaler.fit_transform(X_train)\n    X_val = scaler.transform(X_val)\n    X_test = scaler.transform(X_test)\n    \n    return np.reshape(X_train, (-1,500,1)), np.reshape(X_val, (-1,500,1)), np.reshape(X_test, (-1,500,1))","metadata":{"execution":{"iopub.status.busy":"2022-05-21T16:43:56.093567Z","iopub.execute_input":"2022-05-21T16:43:56.093864Z","iopub.status.idle":"2022-05-21T16:43:56.101115Z","shell.execute_reply.started":"2022-05-21T16:43:56.093834Z","shell.execute_reply":"2022-05-21T16:43:56.100239Z"},"trusted":true},"execution_count":325,"outputs":[]},{"cell_type":"code","source":"input_shape = X_train.shape[1:]","metadata":{"execution":{"iopub.status.busy":"2022-05-21T16:43:56.141508Z","iopub.execute_input":"2022-05-21T16:43:56.141747Z","iopub.status.idle":"2022-05-21T16:43:56.145953Z","shell.execute_reply.started":"2022-05-21T16:43:56.141720Z","shell.execute_reply":"2022-05-21T16:43:56.145245Z"},"trusted":true},"execution_count":326,"outputs":[]},{"cell_type":"code","source":"def timeseries_transform(data, head_size, num_heads, ff_dim, dropout=0):\n    \"\"\"\n    Implement the timeseries transformer here\n    \"\"\"\n    # Normalization and Attention\n    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(data, data)\n    \n    x = layers.Dropout(dropout)(x)\n    res = x + data\n\n    # Feed Forward Part\n    x = layers.LayerNormalization(epsilon=1e-6)(res)\n    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n    x = layers.Dropout(dropout)(x)\n    x = layers.Conv1D(filters=data.shape[-1], kernel_size=1)(x)\n    return x + res","metadata":{"execution":{"iopub.status.busy":"2022-05-21T16:43:56.189824Z","iopub.execute_input":"2022-05-21T16:43:56.190106Z","iopub.status.idle":"2022-05-21T16:43:56.197972Z","shell.execute_reply.started":"2022-05-21T16:43:56.190078Z","shell.execute_reply":"2022-05-21T16:43:56.197244Z"},"trusted":true},"execution_count":327,"outputs":[]},{"cell_type":"code","source":"n_classes = 2","metadata":{"execution":{"iopub.status.busy":"2022-05-21T16:43:56.236153Z","iopub.execute_input":"2022-05-21T16:43:56.236342Z","iopub.status.idle":"2022-05-21T16:43:56.239825Z","shell.execute_reply.started":"2022-05-21T16:43:56.236320Z","shell.execute_reply":"2022-05-21T16:43:56.239113Z"},"trusted":true},"execution_count":328,"outputs":[]},{"cell_type":"code","source":"def build_model(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout=0, mlp_dropout=0):\n    inputs = keras.Input(shape=input_shape)\n    x = inputs\n    for _ in range(num_transformer_blocks):\n        x = timeseries_transform(x, head_size, num_heads, ff_dim, dropout)\n\n    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n    for dim in mlp_units:\n        x = layers.Dense(dim, activation=\"relu\")(x)\n        x = layers.Dropout(mlp_dropout)(x)\n    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n    return keras.Model(inputs, outputs)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T16:43:56.283694Z","iopub.execute_input":"2022-05-21T16:43:56.283886Z","iopub.status.idle":"2022-05-21T16:43:56.289920Z","shell.execute_reply.started":"2022-05-21T16:43:56.283863Z","shell.execute_reply":"2022-05-21T16:43:56.289203Z"},"trusted":true},"execution_count":329,"outputs":[]},{"cell_type":"code","source":"def model_training(X_train, y_train):\n    \"\"\"\n    Train the data with the compatible model\n    \"\"\"\n    \n    input_shape = X_train.shape[1:]\n\n    model = build_model(input_shape, head_size=256, num_heads=4, ff_dim=4, num_transformer_blocks=4, mlp_units=[128], mlp_dropout=0.4, dropout=0.25)\n\n    model.compile(\n        loss=\"sparse_categorical_crossentropy\",\n        optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n        metrics=[\"sparse_categorical_accuracy\"],\n    )\n    \n    model.summary()\n\n    callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n\n    model.fit(X_train, y_train, epochs=10, batch_size=128, callbacks=callbacks)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-21T16:43:56.351840Z","iopub.execute_input":"2022-05-21T16:43:56.352128Z","iopub.status.idle":"2022-05-21T16:43:56.359217Z","shell.execute_reply.started":"2022-05-21T16:43:56.352100Z","shell.execute_reply":"2022-05-21T16:43:56.358294Z"},"trusted":true},"execution_count":330,"outputs":[]},{"cell_type":"code","source":"def metric(y_act, y_pred, model):\n    \"\"\"\n    Standard metrics and plotting should be same\n    Metrics should be computed on validation data(unseen data)\n    1. Balanced accuracy score\n    2. Confusion matrix\n    3. Per-class accuracy\n    \"\"\"\n    \n    cm = metrics.confusion_matrix(y_act, y_pred[:,0])\n    balanced_accuracy = metrics.balanced_accuracy_score(y_act, y_pred[:,0])\n    \n    return cm, balanced_accuracy","metadata":{"execution":{"iopub.status.busy":"2022-05-21T16:43:56.420854Z","iopub.execute_input":"2022-05-21T16:43:56.421048Z","iopub.status.idle":"2022-05-21T16:43:56.426441Z","shell.execute_reply.started":"2022-05-21T16:43:56.421025Z","shell.execute_reply":"2022-05-21T16:43:56.425688Z"},"trusted":true},"execution_count":331,"outputs":[]},{"cell_type":"code","source":"def validation(X_val, y_val, metrics):\n    \"\"\"\n    Comparing the results with provided Series Embedder\n    Plot confusion matrices of self analysis and LSTM with balanced_accuracy\n    \n    \"\"\"\n    \n    score = model.evaluate(X_val, y_val, verbose=1)\n    \n    return score","metadata":{"execution":{"iopub.status.busy":"2022-05-21T16:43:56.525872Z","iopub.execute_input":"2022-05-21T16:43:56.526162Z","iopub.status.idle":"2022-05-21T16:43:56.529907Z","shell.execute_reply.started":"2022-05-21T16:43:56.526134Z","shell.execute_reply":"2022-05-21T16:43:56.529254Z"},"trusted":true},"execution_count":332,"outputs":[]},{"cell_type":"code","source":"def evaluate(X_test, y_act, metric):\n    y_pred = model.predict(X_test, verbose=1)\n    cm, ba = metric(y_act, y_pred[:,0])\n    \n    return y_pred, cm, ba","metadata":{"execution":{"iopub.status.busy":"2022-05-21T16:43:56.595970Z","iopub.execute_input":"2022-05-21T16:43:56.596256Z","iopub.status.idle":"2022-05-21T16:43:56.602496Z","shell.execute_reply.started":"2022-05-21T16:43:56.596227Z","shell.execute_reply":"2022-05-21T16:43:56.601803Z"},"trusted":true},"execution_count":333,"outputs":[]},{"cell_type":"code","source":"path = \"../input/fordadata/data.pkl\"\ndata = load_data(path)\nX, y = preprocess_data(data)\n\nX_train, X_test, X_val, y_train, y_test, y_val = split_train_test(X, y)\nX_train, X_test, X_val = normalization(X_train, X_test, X_val)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T16:43:56.666025Z","iopub.execute_input":"2022-05-21T16:43:56.666308Z","iopub.status.idle":"2022-05-21T16:44:03.519522Z","shell.execute_reply.started":"2022-05-21T16:43:56.666279Z","shell.execute_reply":"2022-05-21T16:44:03.518717Z"},"trusted":true},"execution_count":334,"outputs":[]},{"cell_type":"code","source":"model_self=model_training(X_train, y_train)\n# metrics=metric(val,model_self)\n\n# lstm_cm,lstm_balanced_accuracy=lstm(preprocessed_data,target='labels')\n# metrics_validation = [lstm_cm, lstm_balanced_accuracy]\n# validation(metrics,metrics_validation)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T16:44:03.524804Z","iopub.execute_input":"2022-05-21T16:44:03.527094Z","iopub.status.idle":"2022-05-21T16:46:12.604380Z","shell.execute_reply.started":"2022-05-21T16:44:03.527049Z","shell.execute_reply":"2022-05-21T16:46:12.603707Z"},"trusted":true},"execution_count":335,"outputs":[{"name":"stdout","text":"Model: \"model_8\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_22 (InputLayer)           [(None, 500, 1)]     0                                            \n__________________________________________________________________________________________________\nmulti_head_attention_61 (MultiH (None, 500, 1)       7169        input_22[0][0]                   \n                                                                 input_22[0][0]                   \n__________________________________________________________________________________________________\ndropout_136 (Dropout)           (None, 500, 1)       0           multi_head_attention_61[0][0]    \n__________________________________________________________________________________________________\ntf.__operators__.add_120 (TFOpL (None, 500, 1)       0           dropout_136[0][0]                \n                                                                 input_22[0][0]                   \n__________________________________________________________________________________________________\nlayer_normalization_117 (LayerN (None, 500, 1)       2           tf.__operators__.add_120[0][0]   \n__________________________________________________________________________________________________\nconv1d_120 (Conv1D)             (None, 500, 4)       8           layer_normalization_117[0][0]    \n__________________________________________________________________________________________________\ndropout_137 (Dropout)           (None, 500, 4)       0           conv1d_120[0][0]                 \n__________________________________________________________________________________________________\nconv1d_121 (Conv1D)             (None, 500, 1)       5           dropout_137[0][0]                \n__________________________________________________________________________________________________\ntf.__operators__.add_121 (TFOpL (None, 500, 1)       0           conv1d_121[0][0]                 \n                                                                 tf.__operators__.add_120[0][0]   \n__________________________________________________________________________________________________\nmulti_head_attention_62 (MultiH (None, 500, 1)       7169        tf.__operators__.add_121[0][0]   \n                                                                 tf.__operators__.add_121[0][0]   \n__________________________________________________________________________________________________\ndropout_138 (Dropout)           (None, 500, 1)       0           multi_head_attention_62[0][0]    \n__________________________________________________________________________________________________\ntf.__operators__.add_122 (TFOpL (None, 500, 1)       0           dropout_138[0][0]                \n                                                                 tf.__operators__.add_121[0][0]   \n__________________________________________________________________________________________________\nlayer_normalization_118 (LayerN (None, 500, 1)       2           tf.__operators__.add_122[0][0]   \n__________________________________________________________________________________________________\nconv1d_122 (Conv1D)             (None, 500, 4)       8           layer_normalization_118[0][0]    \n__________________________________________________________________________________________________\ndropout_139 (Dropout)           (None, 500, 4)       0           conv1d_122[0][0]                 \n__________________________________________________________________________________________________\nconv1d_123 (Conv1D)             (None, 500, 1)       5           dropout_139[0][0]                \n__________________________________________________________________________________________________\ntf.__operators__.add_123 (TFOpL (None, 500, 1)       0           conv1d_123[0][0]                 \n                                                                 tf.__operators__.add_122[0][0]   \n__________________________________________________________________________________________________\nmulti_head_attention_63 (MultiH (None, 500, 1)       7169        tf.__operators__.add_123[0][0]   \n                                                                 tf.__operators__.add_123[0][0]   \n__________________________________________________________________________________________________\ndropout_140 (Dropout)           (None, 500, 1)       0           multi_head_attention_63[0][0]    \n__________________________________________________________________________________________________\ntf.__operators__.add_124 (TFOpL (None, 500, 1)       0           dropout_140[0][0]                \n                                                                 tf.__operators__.add_123[0][0]   \n__________________________________________________________________________________________________\nlayer_normalization_119 (LayerN (None, 500, 1)       2           tf.__operators__.add_124[0][0]   \n__________________________________________________________________________________________________\nconv1d_124 (Conv1D)             (None, 500, 4)       8           layer_normalization_119[0][0]    \n__________________________________________________________________________________________________\ndropout_141 (Dropout)           (None, 500, 4)       0           conv1d_124[0][0]                 \n__________________________________________________________________________________________________\nconv1d_125 (Conv1D)             (None, 500, 1)       5           dropout_141[0][0]                \n__________________________________________________________________________________________________\ntf.__operators__.add_125 (TFOpL (None, 500, 1)       0           conv1d_125[0][0]                 \n                                                                 tf.__operators__.add_124[0][0]   \n__________________________________________________________________________________________________\nmulti_head_attention_64 (MultiH (None, 500, 1)       7169        tf.__operators__.add_125[0][0]   \n                                                                 tf.__operators__.add_125[0][0]   \n__________________________________________________________________________________________________\ndropout_142 (Dropout)           (None, 500, 1)       0           multi_head_attention_64[0][0]    \n__________________________________________________________________________________________________\ntf.__operators__.add_126 (TFOpL (None, 500, 1)       0           dropout_142[0][0]                \n                                                                 tf.__operators__.add_125[0][0]   \n__________________________________________________________________________________________________\nlayer_normalization_120 (LayerN (None, 500, 1)       2           tf.__operators__.add_126[0][0]   \n__________________________________________________________________________________________________\nconv1d_126 (Conv1D)             (None, 500, 4)       8           layer_normalization_120[0][0]    \n__________________________________________________________________________________________________\ndropout_143 (Dropout)           (None, 500, 4)       0           conv1d_126[0][0]                 \n__________________________________________________________________________________________________\nconv1d_127 (Conv1D)             (None, 500, 1)       5           dropout_143[0][0]                \n__________________________________________________________________________________________________\ntf.__operators__.add_127 (TFOpL (None, 500, 1)       0           conv1d_127[0][0]                 \n                                                                 tf.__operators__.add_126[0][0]   \n__________________________________________________________________________________________________\nglobal_average_pooling1d_15 (Gl (None, 500)          0           tf.__operators__.add_127[0][0]   \n__________________________________________________________________________________________________\ndense_23 (Dense)                (None, 128)          64128       global_average_pooling1d_15[0][0]\n__________________________________________________________________________________________________\ndropout_144 (Dropout)           (None, 128)          0           dense_23[0][0]                   \n__________________________________________________________________________________________________\ndense_24 (Dense)                (None, 2)            258         dropout_144[0][0]                \n==================================================================================================\nTotal params: 93,122\nTrainable params: 93,122\nNon-trainable params: 0\n__________________________________________________________________________________________________\nEpoch 1/10\n25/25 [==============================] - 15s 506ms/step - loss: 0.7568 - sparse_categorical_accuracy: 0.4975\nEpoch 2/10\n25/25 [==============================] - 13s 505ms/step - loss: 0.7167 - sparse_categorical_accuracy: 0.4971\nEpoch 3/10\n25/25 [==============================] - 13s 504ms/step - loss: 0.7071 - sparse_categorical_accuracy: 0.5175\nEpoch 4/10\n25/25 [==============================] - 13s 506ms/step - loss: 0.7034 - sparse_categorical_accuracy: 0.5159\nEpoch 5/10\n25/25 [==============================] - 13s 504ms/step - loss: 0.6968 - sparse_categorical_accuracy: 0.5314\nEpoch 6/10\n25/25 [==============================] - 13s 504ms/step - loss: 0.6849 - sparse_categorical_accuracy: 0.5594\nEpoch 7/10\n25/25 [==============================] - 13s 505ms/step - loss: 0.6841 - sparse_categorical_accuracy: 0.5518\nEpoch 8/10\n25/25 [==============================] - 13s 505ms/step - loss: 0.6831 - sparse_categorical_accuracy: 0.5639\nEpoch 9/10\n25/25 [==============================] - 13s 504ms/step - loss: 0.6764 - sparse_categorical_accuracy: 0.5699\nEpoch 10/10\n25/25 [==============================] - 13s 505ms/step - loss: 0.6748 - sparse_categorical_accuracy: 0.5731\n","output_type":"stream"}]}]}